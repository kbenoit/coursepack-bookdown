<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>MY451 Introduction to Quantitative Analysis</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="This course is intended for those with little or no past training in quantitative methods. The course is an intensive introduction to some of the principles and methods of statistical analysis in social research. Topics covered in MY451 include descriptive statistics, basic ideas of inference and estimation, contingency tables and an introduction to linear regression models.">
  <meta name="generator" content="bookdown 0.1.7 and GitBook 2.6.7">

  <meta property="og:title" content="MY451 Introduction to Quantitative Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This course is intended for those with little or no past training in quantitative methods. The course is an intensive introduction to some of the principles and methods of statistical analysis in social research. Topics covered in MY451 include descriptive statistics, basic ideas of inference and estimation, contingency tables and an introduction to linear regression models." />
  <meta name="github-repo" content="kbenoit/coursepack-bookdown" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="MY451 Introduction to Quantitative Analysis" />
  
  <meta name="twitter:description" content="This course is intended for those with little or no past training in quantitative methods. The course is an intensive introduction to some of the principles and methods of statistical analysis in social research. Topics covered in MY451 include descriptive statistics, basic ideas of inference and estimation, contingency tables and an introduction to linear regression models." />
  

<meta name="author" content="Jouni Kuha III of Hannover">
<meta name="author" content="Department of Methodology">
<meta name="author" content="London School of Economics and Political Science">


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="c-intro.html">
<link rel="next" href="c-samples.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MY451 Introduction to Quantitative Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Course information</a></li>
<li class="chapter" data-level="1" data-path="c-intro.html"><a href="c-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="c-intro.html"><a href="c-intro.html#s-intro-purpose"><i class="fa fa-check"></i><b>1.1</b> What is the purpose of this course?</a></li>
<li class="chapter" data-level="1.2" data-path="c-intro.html"><a href="c-intro.html#s-intro-definitions"><i class="fa fa-check"></i><b>1.2</b> Some basic definitions</a><ul>
<li class="chapter" data-level="1.2.1" data-path="c-intro.html"><a href="c-intro.html#ss-intro-def-subj"><i class="fa fa-check"></i><b>1.2.1</b> Subjects and variables</a></li>
<li class="chapter" data-level="1.2.2" data-path="c-intro.html"><a href="c-intro.html#ss-intro-def-vartypes"><i class="fa fa-check"></i><b>1.2.2</b> Types of variables</a></li>
<li class="chapter" data-level="1.2.3" data-path="c-intro.html"><a href="c-intro.html#ss-intro-def-descr"><i class="fa fa-check"></i><b>1.2.3</b> Description and inference</a></li>
<li class="chapter" data-level="1.2.4" data-path="c-intro.html"><a href="c-intro.html#ss-intro-def-assoc"><i class="fa fa-check"></i><b>1.2.4</b> Association and causation</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="c-intro.html"><a href="c-intro.html#s-intro-outline"><i class="fa fa-check"></i><b>1.3</b> Outline of the course</a></li>
<li class="chapter" data-level="1.4" data-path="c-intro.html"><a href="c-intro.html#s-intro-maths"><i class="fa fa-check"></i><b>1.4</b> The use of mathematics and computing</a><ul>
<li class="chapter" data-level="1.4.1" data-path="c-intro.html"><a href="c-intro.html#symbolic-mathematics-and-mathematical-notation"><i class="fa fa-check"></i><b>1.4.1</b> Symbolic mathematics and mathematical notation</a></li>
<li class="chapter" data-level="1.4.2" data-path="c-intro.html"><a href="c-intro.html#computing-1"><i class="fa fa-check"></i><b>1.4.2</b> Computing</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="c-descr1.html"><a href="c-descr1.html"><i class="fa fa-check"></i><b>2</b> Descriptive statistics</a><ul>
<li class="chapter" data-level="2.1" data-path="c-descr1.html"><a href="c-descr1.html#s-descr1-intro"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="c-descr1.html"><a href="c-descr1.html#s-descr1-examples"><i class="fa fa-check"></i><b>2.2</b> Example data sets</a></li>
<li class="chapter" data-level="2.3" data-path="c-descr1.html"><a href="c-descr1.html#s-descr1-1cat"><i class="fa fa-check"></i><b>2.3</b> Single categorical variable</a><ul>
<li class="chapter" data-level="2.3.1" data-path="c-descr1.html"><a href="c-descr1.html#ss-descr1-1cat-distr"><i class="fa fa-check"></i><b>2.3.1</b> Describing the sample distribution</a></li>
<li class="chapter" data-level="2.3.2" data-path="c-descr1.html"><a href="c-descr1.html#ss-descr1-1cat-tables"><i class="fa fa-check"></i><b>2.3.2</b> Tabular methods: Tables of frequencies</a></li>
<li class="chapter" data-level="2.3.3" data-path="c-descr1.html"><a href="c-descr1.html#ss-descr1-1cat-charts"><i class="fa fa-check"></i><b>2.3.3</b> Graphical methods: Bar charts</a></li>
<li class="chapter" data-level="2.3.4" data-path="c-descr1.html"><a href="c-descr1.html#ss-descr1-1cat-descriptives"><i class="fa fa-check"></i><b>2.3.4</b> Simple descriptive statistics</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="c-descr1.html"><a href="c-descr1.html#s-descr1-2cat"><i class="fa fa-check"></i><b>2.4</b> Two categorical variables</a><ul>
<li class="chapter" data-level="2.4.1" data-path="c-descr1.html"><a href="c-descr1.html#ss-descr1-2cat-tables"><i class="fa fa-check"></i><b>2.4.1</b> Two-way contingency tables</a></li>
<li class="chapter" data-level="2.4.2" data-path="c-descr1.html"><a href="c-descr1.html#ss-descr1-2cat-cond"><i class="fa fa-check"></i><b>2.4.2</b> Conditional proportions</a></li>
<li class="chapter" data-level="2.4.3" data-path="c-descr1.html"><a href="c-descr1.html#ss-descr1-2cat-assoc"><i class="fa fa-check"></i><b>2.4.3</b> Conditional distributions and associations</a></li>
<li class="chapter" data-level="2.4.4" data-path="c-descr1.html"><a href="c-descr1.html#ss-descr1-2cat-descr"><i class="fa fa-check"></i><b>2.4.4</b> Describing an association using conditional proportions</a></li>
<li class="chapter" data-level="2.4.5" data-path="c-descr1.html"><a href="c-descr1.html#ss-descr1-2cat-gamma"><i class="fa fa-check"></i><b>2.4.5</b> A measure of association for ordinal variables</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="c-descr1.html"><a href="c-descr1.html#s-descr1-1cont"><i class="fa fa-check"></i><b>2.5</b> Sample distributions of a single continuous variable</a><ul>
<li class="chapter" data-level="2.5.1" data-path="c-descr1.html"><a href="c-descr1.html#ss-descr1-1cont-tab"><i class="fa fa-check"></i><b>2.5.1</b> Tabular methods</a></li>
<li class="chapter" data-level="2.5.2" data-path="c-descr1.html"><a href="c-descr1.html#ss-descr1-1cont-graphs"><i class="fa fa-check"></i><b>2.5.2</b> Graphical methods</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="c-descr1.html"><a href="c-descr1.html#s-descr1-nums"><i class="fa fa-check"></i><b>2.6</b> Numerical descriptive statistics</a><ul>
<li class="chapter" data-level="2.6.1" data-path="c-descr1.html"><a href="c-descr1.html#ss-descr1-nums-central"><i class="fa fa-check"></i><b>2.6.1</b> Measures of central tendency</a></li>
<li class="chapter" data-level="2.6.2" data-path="c-descr1.html"><a href="c-descr1.html#ss-descr1-nums-variation"><i class="fa fa-check"></i><b>2.6.2</b> Measures of variation</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="c-descr1.html"><a href="c-descr1.html#s-descr1-2cont"><i class="fa fa-check"></i><b>2.7</b> Associations which involve continuous variables</a></li>
<li class="chapter" data-level="2.8" data-path="c-descr1.html"><a href="c-descr1.html#s-descr1-presentation"><i class="fa fa-check"></i><b>2.8</b> Presentation of tables and graphs</a></li>
<li class="chapter" data-level="2.9" data-path="c-descr1.html"><a href="c-descr1.html#s-descr1-app"><i class="fa fa-check"></i><b>2.9</b> Appendix: Country data</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="c-samples.html"><a href="c-samples.html"><i class="fa fa-check"></i><b>3</b> Samples and populations</a><ul>
<li class="chapter" data-level="3.1" data-path="c-samples.html"><a href="c-samples.html#s-samples-intro"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="c-samples.html"><a href="c-samples.html#s-samples-finpops"><i class="fa fa-check"></i><b>3.2</b> Finite populations</a></li>
<li class="chapter" data-level="3.3" data-path="c-samples.html"><a href="c-samples.html#s-samples-samples"><i class="fa fa-check"></i><b>3.3</b> Samples from finite populations</a></li>
<li class="chapter" data-level="3.4" data-path="c-samples.html"><a href="c-samples.html#s-samples-infpops"><i class="fa fa-check"></i><b>3.4</b> Conceptual and infinite populations</a></li>
<li class="chapter" data-level="3.5" data-path="c-samples.html"><a href="c-samples.html#s-samples-popdistrs"><i class="fa fa-check"></i><b>3.5</b> Population distributions</a></li>
<li class="chapter" data-level="3.6" data-path="c-samples.html"><a href="c-samples.html#s-samples-inference"><i class="fa fa-check"></i><b>3.6</b> Need for statistical inference</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="c-tables.html"><a href="c-tables.html"><i class="fa fa-check"></i><b>4</b> Statistical inference for two-way tables</a><ul>
<li class="chapter" data-level="4.1" data-path="c-tables.html"><a href="c-tables.html#s-tables-intro"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="c-tables.html"><a href="c-tables.html#s-tables-tests"><i class="fa fa-check"></i><b>4.2</b> Significance tests</a></li>
<li class="chapter" data-level="4.3" data-path="c-tables.html"><a href="c-tables.html#s-tables-chi2test"><i class="fa fa-check"></i><b>4.3</b> The chi-square test of independence</a><ul>
<li class="chapter" data-level="4.3.1" data-path="c-tables.html"><a href="c-tables.html#ss-tables-chi2test-null"><i class="fa fa-check"></i><b>4.3.1</b> Hypotheses</a></li>
<li class="chapter" data-level="4.3.2" data-path="c-tables.html"><a href="c-tables.html#ss-tables-chi2test-ass"><i class="fa fa-check"></i><b>4.3.2</b> Assumptions of a significance test</a></li>
<li class="chapter" data-level="4.3.3" data-path="c-tables.html"><a href="c-tables.html#ss-tables-chi2test-stat"><i class="fa fa-check"></i><b>4.3.3</b> The test statistic</a></li>
<li class="chapter" data-level="4.3.4" data-path="c-tables.html"><a href="c-tables.html#ss-tables-chi2test-sdist"><i class="fa fa-check"></i><b>4.3.4</b> The sampling distribution of the test statistic</a></li>
<li class="chapter" data-level="4.3.5" data-path="c-tables.html"><a href="c-tables.html#ss-tables-chi2test-Pval"><i class="fa fa-check"></i><b>4.3.5</b> The <span class="math inline">\(P\)</span>-value</a></li>
<li class="chapter" data-level="4.3.6" data-path="c-tables.html"><a href="c-tables.html#ss-tables-chi2test-conclusions"><i class="fa fa-check"></i><b>4.3.6</b> Drawing conclusions from a test</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="c-tables.html"><a href="c-tables.html#s-tables-summary"><i class="fa fa-check"></i><b>4.4</b> Summary of the chi-square test of independence</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="c-probs.html"><a href="c-probs.html"><i class="fa fa-check"></i><b>5</b> Inference for population proportions</a><ul>
<li class="chapter" data-level="5.1" data-path="c-probs.html"><a href="c-probs.html#s-probs-intro"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="c-probs.html"><a href="c-probs.html#s-probs-examples"><i class="fa fa-check"></i><b>5.2</b> Examples</a></li>
<li class="chapter" data-level="5.3" data-path="c-probs.html"><a href="c-probs.html#s-probs-distribution"><i class="fa fa-check"></i><b>5.3</b> Probability distribution of a dichotomous variable</a></li>
<li class="chapter" data-level="5.4" data-path="c-probs.html"><a href="c-probs.html#s-probs-pointest"><i class="fa fa-check"></i><b>5.4</b> Point estimation of a population probability</a></li>
<li class="chapter" data-level="5.5" data-path="c-probs.html"><a href="c-probs.html#s-probs-test1sample"><i class="fa fa-check"></i><b>5.5</b> Significance test of a single proportion</a><ul>
<li class="chapter" data-level="5.5.1" data-path="c-probs.html"><a href="c-probs.html#ss-probs-test1sample-hypotheses"><i class="fa fa-check"></i><b>5.5.1</b> Null and alternative hypotheses</a></li>
<li class="chapter" data-level="5.5.2" data-path="c-probs.html"><a href="c-probs.html#ss-probs-test1sample-teststatistic"><i class="fa fa-check"></i><b>5.5.2</b> The test statistic</a></li>
<li class="chapter" data-level="5.5.3" data-path="c-probs.html"><a href="c-probs.html#ss-probs-test1sample-samplingd"><i class="fa fa-check"></i><b>5.5.3</b> The sampling distribution of the test statistic and <span class="math inline">\(P\)</span>-values</a></li>
<li class="chapter" data-level="5.5.4" data-path="c-probs.html"><a href="c-probs.html#ss-probs-test1sample-conclusions"><i class="fa fa-check"></i><b>5.5.4</b> Conclusions from the test</a></li>
<li class="chapter" data-level="5.5.5" data-path="c-probs.html"><a href="c-probs.html#ss-probs-test1sample-summary"><i class="fa fa-check"></i><b>5.5.5</b> Summary of the test</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="c-probs.html"><a href="c-probs.html#s-probs-1sampleci"><i class="fa fa-check"></i><b>5.6</b> Confidence interval for a single proportion</a><ul>
<li class="chapter" data-level="5.6.1" data-path="c-probs.html"><a href="c-probs.html#s-probs-1sampleci-intro"><i class="fa fa-check"></i><b>5.6.1</b> Introduction</a></li>
<li class="chapter" data-level="5.6.2" data-path="c-probs.html"><a href="c-probs.html#s-probs-1sampleci-calc"><i class="fa fa-check"></i><b>5.6.2</b> Calculation of the interval</a></li>
<li class="chapter" data-level="5.6.3" data-path="c-probs.html"><a href="c-probs.html#s-probs-1sampleci-int"><i class="fa fa-check"></i><b>5.6.3</b> Interpretation of confidence intervals</a></li>
<li class="chapter" data-level="5.6.4" data-path="c-probs.html"><a href="c-probs.html#ss-means-ci-vstests"><i class="fa fa-check"></i><b>5.6.4</b> Confidence intervals vs. significance tests</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="c-probs.html"><a href="c-probs.html#s-probs-2samples"><i class="fa fa-check"></i><b>5.7</b> Inference for comparing two proportions</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="c-contd.html"><a href="c-contd.html"><i class="fa fa-check"></i><b>6</b> Continuous variables: Population and sampling distributions</a><ul>
<li class="chapter" data-level="6.1" data-path="c-contd.html"><a href="c-contd.html#s-contd-intro"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="c-contd.html"><a href="c-contd.html#s-contd-popdistrs"><i class="fa fa-check"></i><b>6.2</b> Population distributions of continuous variables</a><ul>
<li class="chapter" data-level="6.2.1" data-path="c-contd.html"><a href="c-contd.html#ss-contd-popdistrs-params"><i class="fa fa-check"></i><b>6.2.1</b> Population parameters and their point estimates</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="c-contd.html"><a href="c-contd.html#s-contd-probdistrs"><i class="fa fa-check"></i><b>6.3</b> Probability distributions of continuous variables</a><ul>
<li class="chapter" data-level="6.3.1" data-path="c-contd.html"><a href="c-contd.html#ss-contd-probdistrs-general"><i class="fa fa-check"></i><b>6.3.1</b> General comments</a></li>
<li class="chapter" data-level="6.3.2" data-path="c-contd.html"><a href="c-contd.html#ss-contd-probdistrs-normal"><i class="fa fa-check"></i><b>6.3.2</b> The normal distribution as a population distribution</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="c-contd.html"><a href="c-contd.html#s-contd-clt"><i class="fa fa-check"></i><b>6.4</b> The normal distribution as a sampling distribution</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="c-means.html"><a href="c-means.html"><i class="fa fa-check"></i><b>7</b> Analysis of population means</a><ul>
<li class="chapter" data-level="7.1" data-path="c-means.html"><a href="c-means.html#s-means-intro"><i class="fa fa-check"></i><b>7.1</b> Introduction and examples</a></li>
<li class="chapter" data-level="7.2" data-path="c-means.html"><a href="c-means.html#s-means-descr"><i class="fa fa-check"></i><b>7.2</b> Descriptive statistics for comparisons of groups</a><ul>
<li class="chapter" data-level="7.2.1" data-path="c-means.html"><a href="c-means.html#ss-means-descr-graphs"><i class="fa fa-check"></i><b>7.2.1</b> Graphical methods of comparing sample distributions</a></li>
<li class="chapter" data-level="7.2.2" data-path="c-means.html"><a href="c-means.html#ss-means-descr-tables"><i class="fa fa-check"></i><b>7.2.2</b> Comparing summary statistics</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="c-means.html"><a href="c-means.html#s-means-inference"><i class="fa fa-check"></i><b>7.3</b> Inference for two means from independent samples</a><ul>
<li class="chapter" data-level="7.3.1" data-path="c-means.html"><a href="c-means.html#ss-means-inference-intro"><i class="fa fa-check"></i><b>7.3.1</b> Aims of the analysis</a></li>
<li class="chapter" data-level="7.3.2" data-path="c-means.html"><a href="c-means.html#ss-means-inference-test"><i class="fa fa-check"></i><b>7.3.2</b> Significance testing: The two-sample <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="7.3.3" data-path="c-means.html"><a href="c-means.html#ss-means-inference-ci"><i class="fa fa-check"></i><b>7.3.3</b> Confidence intervals for a difference of two means</a></li>
<li class="chapter" data-level="7.3.4" data-path="c-means.html"><a href="c-means.html#ss-means-inference-variants"><i class="fa fa-check"></i><b>7.3.4</b> Variants of the test and confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="c-means.html"><a href="c-means.html#s-means-1sample"><i class="fa fa-check"></i><b>7.4</b> Tests and confidence intervals for a single mean</a></li>
<li class="chapter" data-level="7.5" data-path="c-means.html"><a href="c-means.html#s-means-dependent"><i class="fa fa-check"></i><b>7.5</b> Inference for dependent samples</a></li>
<li class="chapter" data-level="7.6" data-path="c-means.html"><a href="c-means.html#s-means-tests3"><i class="fa fa-check"></i><b>7.6</b> Further comments on significance tests</a><ul>
<li class="chapter" data-level="7.6.1" data-path="c-means.html"><a href="c-means.html#ss-means-tests3-errors"><i class="fa fa-check"></i><b>7.6.1</b> Different types of error</a></li>
<li class="chapter" data-level="7.6.2" data-path="c-means.html"><a href="c-means.html#ss-means-tests3-power"><i class="fa fa-check"></i><b>7.6.2</b> Power of significance tests</a></li>
<li class="chapter" data-level="7.6.3" data-path="c-means.html"><a href="c-means.html#ss-means-tests3-importance"><i class="fa fa-check"></i><b>7.6.3</b> Significance vs. importance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="c-regression.html"><a href="c-regression.html"><i class="fa fa-check"></i><b>8</b> Linear regression models</a><ul>
<li class="chapter" data-level="8.1" data-path="c-regression.html"><a href="c-regression.html#s-regression-intro"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="c-regression.html"><a href="c-regression.html#s-regression-descr"><i class="fa fa-check"></i><b>8.2</b> Describing association between two continuous variables</a><ul>
<li class="chapter" data-level="8.2.1" data-path="c-regression.html"><a href="c-regression.html#ss-regression-descr-intro"><i class="fa fa-check"></i><b>8.2.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2.2" data-path="c-regression.html"><a href="c-regression.html#ss-regression-descr-plots"><i class="fa fa-check"></i><b>8.2.2</b> Graphical methods</a></li>
<li class="chapter" data-level="8.2.3" data-path="c-regression.html"><a href="c-regression.html#ss-regression-descr-assoc"><i class="fa fa-check"></i><b>8.2.3</b> Linear associations</a></li>
<li class="chapter" data-level="8.2.4" data-path="c-regression.html"><a href="c-regression.html#ss-regression-descr-corr"><i class="fa fa-check"></i><b>8.2.4</b> Measures of association: covariance and correlation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="c-regression.html"><a href="c-regression.html#s-regression-simple"><i class="fa fa-check"></i><b>8.3</b> Simple linear regression models</a><ul>
<li class="chapter" data-level="8.3.1" data-path="c-regression.html"><a href="c-regression.html#ss-regression-simple-intro"><i class="fa fa-check"></i><b>8.3.1</b> Introduction</a></li>
<li class="chapter" data-level="8.3.2" data-path="c-regression.html"><a href="c-regression.html#ss-regression-simple-def"><i class="fa fa-check"></i><b>8.3.2</b> Definition of the model</a></li>
<li class="chapter" data-level="8.3.3" data-path="c-regression.html"><a href="c-regression.html#ss-regression-simple-int"><i class="fa fa-check"></i><b>8.3.3</b> Interpretation of the model parameters</a></li>
<li class="chapter" data-level="8.3.4" data-path="c-regression.html"><a href="c-regression.html#ss-regression-simple-est"><i class="fa fa-check"></i><b>8.3.4</b> Estimation of the parameters</a></li>
<li class="chapter" data-level="8.3.5" data-path="c-regression.html"><a href="c-regression.html#ss-regression-simple-inf"><i class="fa fa-check"></i><b>8.3.5</b> Statistical inference for the regression coefficients</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="c-regression.html"><a href="c-regression.html#s-regression-causality"><i class="fa fa-check"></i><b>8.4</b> Interlude: Association and causality</a></li>
<li class="chapter" data-level="8.5" data-path="c-regression.html"><a href="c-regression.html#s-regression-multiple"><i class="fa fa-check"></i><b>8.5</b> Multiple linear regression models</a><ul>
<li class="chapter" data-level="8.5.1" data-path="c-regression.html"><a href="c-regression.html#ss-regression-multiple-intro"><i class="fa fa-check"></i><b>8.5.1</b> Introduction</a></li>
<li class="chapter" data-level="8.5.2" data-path="c-regression.html"><a href="c-regression.html#ss-regression-multiple-def"><i class="fa fa-check"></i><b>8.5.2</b> Definition of the model</a></li>
<li class="chapter" data-level="8.5.3" data-path="c-regression.html"><a href="c-regression.html#ss-regression-multiple-unchanged"><i class="fa fa-check"></i><b>8.5.3</b> Unchanged elements from simple linear models</a></li>
<li class="chapter" data-level="8.5.4" data-path="c-regression.html"><a href="c-regression.html#ss-regression-multiple-beta"><i class="fa fa-check"></i><b>8.5.4</b> Interpretation and inference for the regression coefficients</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="c-regression.html"><a href="c-regression.html#s-regression-dummies"><i class="fa fa-check"></i><b>8.6</b> Including categorical explanatory variables</a><ul>
<li class="chapter" data-level="8.6.1" data-path="c-regression.html"><a href="c-regression.html#ss-regression-dummies-def"><i class="fa fa-check"></i><b>8.6.1</b> Dummy variables</a></li>
<li class="chapter" data-level="8.6.2" data-path="c-regression.html"><a href="c-regression.html#ss-regression-dummies-example"><i class="fa fa-check"></i><b>8.6.2</b> A second example</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="c-regression.html"><a href="c-regression.html#s-regression-rest"><i class="fa fa-check"></i><b>8.7</b> Other issues in linear regression modelling</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="c-3waytables.html"><a href="c-3waytables.html"><i class="fa fa-check"></i><b>9</b> Analysis of 3-way contingency tables</a></li>
<li class="chapter" data-level="10" data-path="c-more.html"><a href="c-more.html"><i class="fa fa-check"></i><b>10</b> More statistics…</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#computer-classes"><i class="fa fa-check"></i>Computer classes</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#general-instructions"><i class="fa fa-check"></i>General instructions</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#introduction-to-spss"><i class="fa fa-check"></i>Introduction to SPSS</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#week-2-class-descriptive-statistics-for-categorical-data-and-entering-data"><i class="fa fa-check"></i>WEEK 2 class: Descriptive statistics for categorical data, and entering data</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#week-3-class"><i class="fa fa-check"></i>WEEK 3 class</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#week-4-class-two-way-contingency-tables"><i class="fa fa-check"></i>WEEK 4 class: Two-way contingency tables</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#week-5-class-inference-for-two-population-means"><i class="fa fa-check"></i>WEEK 5 class: Inference for two population means</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#week-7-class-inference-for-population-proportions"><i class="fa fa-check"></i>WEEK 7 class: Inference for population proportions</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#week-7-class-correlation-and-simple-linear-regression-1"><i class="fa fa-check"></i>WEEK 7 class: Correlation and simple linear regression 1</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#week-8-class-simple-linear-regression-and-3-way-tables"><i class="fa fa-check"></i>WEEK 8 class: Simple linear regression and 3-way tables</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#week-9-class-multiple-linear-regression"><i class="fa fa-check"></i>WEEK 9 class: Multiple linear regression</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#week-10-class-review-and-multiple-linear-regression"><i class="fa fa-check"></i>WEEK 10 class: Review and Multiple linear regression</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#statistical-tables"><i class="fa fa-check"></i>Statistical tables</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#table-of-standard-normal-tail-probabilities"><i class="fa fa-check"></i>Table of standard normal tail probabilities</a></li>
<li><a href="appendix.html#table-of-critical-values-for-t-distributions">Table of critical values for <span class="math inline">\(t\)</span>-distributions</a></li>
<li><a href="appendix.html#table-of-critical-values-for-chi2-distributions">Table of critical values for <span class="math inline">\(\chi^{2}\)</span> distributions</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/kbenoit/coursepack-bookdown/" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MY451 Introduction to Quantitative Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="c-descr1" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Descriptive statistics</h1>
<div id="s-descr1-intro" class="section level2">
<h2><span class="header-section-number">2.1</span> Introduction</h2>
<p>This chapter introduces some common descriptive statistical methods. It is organised around two dichotomies:</p>
<ul>
<li><p>Methods that are used only for variables with small numbers of values, vs. methods that are used also or only for variables with many values (see the end of Section <a href="c-intro.html#ss-intro-def-vartypes">1.2.2</a> for more on this distinction). The former include, in particular, descriptive methods for categorical variables, and the latter the methods for continuous variables.</p></li>
<li><p><strong>Univariate</strong> descriptive methods which consider only one variable at a time, vs. <strong>bivariate</strong> methods which aim to describe the association between <em>two</em> variables.</p></li>
</ul>
<p>Section <a href="c-descr1.html#s-descr1-1cat">2.3</a> describes univariate methods for categorical variables and Section <a href="c-descr1.html#s-descr1-2cat">2.4</a> bivariate methods for cases where both variables are categorical. Sections <a href="c-descr1.html#s-descr1-1cont">2.5</a> and <a href="c-descr1.html#s-descr1-nums">2.6</a> cover univariate methods which are mostly used for continuous variables. Section <a href="c-descr1.html#s-descr1-2cont">2.7</a> lists some bivariate methods where at least one variable is continuous; these methods are discussed in detail elsewhere in the coursepack. The chapter concludes with some general guidelines for presentation of descriptive tables and graphs in Section <a href="c-descr1.html#s-descr1-presentation">2.8</a>.</p>
</div>
<div id="s-descr1-examples" class="section level2">
<h2><span class="header-section-number">2.2</span> Example data sets</h2>
<p>Two examples are used to illustrate the methods throughout this chapter:</p>
<p><em>Example: Country data</em> </p>
<p>Consider data for 155 countries on three variables:</p>
<ul>
<li><p>The <strong>region</strong> where the country is located, coded as 1=Africa, 2=Asia, 3=Europe, 4=Latin America, 5=Northern America, 6=Oceania.</p></li>
<li><p>A measure of the level of <strong>democracy</strong> in the country, measured on an 11-point scale from 0 (lowest level of democracy) to 10 (highest).</p></li>
<li><p>Gross Domestic Product (<strong>GDP</strong>) per capita, in thousands of U.S. dollars.</p></li>
</ul>
<p>Further information on the variables is given in the appendix to this chapter (Section <a href="c-descr1.html#s-descr1-app">2.9</a>), together with the whole data set, shown in Table <a href="c-descr1.html#tab:t-countrydata">2.14</a>.</p>
<p>Region is clearly a discrete (and categorical), nominal-level variable, and GDP a continuous, interval-level variable. The democracy index is discrete; it is most realistic to consider its measurement level to be ordinal, and it is regarded as such in this chapter. However, it is the kind of variable which might in many analyses be treated instead as an effectively continuous, interval-level variable.</p>
<p><em>Example: Survey data on attitudes towards income redistribution</em></p>
<p>The data for the second example come from Round 5 of the European Social Survey (ESS), which was carried out in 2010.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> The survey was fielded in 28 countries, but here we use only data from 2344 respondents in the UK. Two variables are considered:</p>
<ul>
<li><p><strong>Sex</strong> of the respondent, coded as 1=Male, 2=Female.</p></li>
<li><p>Answer to the following survey question:<br />
<em>“The government should take measures to reduce differences in income levels”</em>,<br />
with five response options coded as “Agree strongly”=1, “Agree”=2, “Neither agree nor disagree”=3, “Disagree”=4, and “Disagree strongly”=5. This is a measure of the respondent’s <strong>attitude</strong> towards income redistribution.</p></li>
</ul>
<p>Both of these are discrete, categorical variables. Sex is binary and attitude is ordinal.</p>
<p>Attitudes towards income redistribution are an example of the broader topic of public opinion on welfare state policies. This is a large topic of classic and current interest in the social sciences, and questions on it have been included in many public opinion surveys.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> Of key interest is to explore the how people’s attitudes are associated with their individual characteristics (including such factors as age, sex, education and income) and the contexts in which they live (for example the type of welfare regime adopted in their country). In section <a href="c-descr1.html#s-descr1-2cat">2.4</a> below we use descriptive statistics to examine such associations between sex and attitude in this sample.</p>
</div>
<div id="s-descr1-1cat" class="section level2">
<h2><span class="header-section-number">2.3</span> Single categorical variable</h2>
<div id="ss-descr1-1cat-distr" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Describing the sample distribution</h3>
<p>The term <em>distribution</em> is very important in statistics. In this section we consider the distribution of a single variable in the observed data, i.e. its <em>sample distribution</em>:</p>
<ul>
<li>The <strong>sample distribution</strong> of a variable consists of a list of the values of the variable which occur in a sample, together with the number of times each value occurs.</li>
</ul>
<p>Later we will discuss other kinds of distributions, such as population, probability and sampling distributions, but they will all be variants of the same concept.</p>
<p>The task of descriptive statistics for a single variable is to summarize the sample distribution or some features of it. This can be done in the form of tables, graphs or single numbers.</p>
</div>
<div id="ss-descr1-1cat-tables" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Tabular methods: Tables of frequencies</h3>
<p>When a variable has only a limited number of distinct values, its sample distribution can be summarized directly from the definition given above. In other words, we simply count and display the number of times each of the values appears in the data. One way to do the display is as a table, like the ones for region and the democracy index in the country data, and attitude in the survey example, which are shown in Tables <a href="c-descr1.html#tab:t-region">2.1</a>, <a href="c-descr1.html#tab:t-democ">2.2</a> and <a href="c-descr1.html#tab:t-attitude">2.3</a> respectively.</p>
<table>
<caption><span id="tab:t-region">Table 2.1: </span>Frequency distribution of the region variable in the country data.</caption>
<thead>
<tr class="header">
<th align="left">Region</th>
<th align="right">Frequency</th>
<th align="right">Proportion</th>
<th align="right">%</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Africa</td>
<td align="right">48</td>
<td align="right">0.310</td>
<td align="right">31.0</td>
</tr>
<tr class="even">
<td align="left">Asia</td>
<td align="right">44</td>
<td align="right">0.284</td>
<td align="right">28.4</td>
</tr>
<tr class="odd">
<td align="left">Europe</td>
<td align="right">34</td>
<td align="right">0.219</td>
<td align="right">21.9</td>
</tr>
<tr class="even">
<td align="left">Latin America</td>
<td align="right">23</td>
<td align="right">0.148</td>
<td align="right">14.8</td>
</tr>
<tr class="odd">
<td align="left">Northern America</td>
<td align="right">2</td>
<td align="right">0.013</td>
<td align="right">1.3</td>
</tr>
<tr class="even">
<td align="left">Oceania</td>
<td align="right">4</td>
<td align="right">0.026</td>
<td align="right">2.6</td>
</tr>
<tr class="odd">
<td align="left">Total</td>
<td align="right">155</td>
<td align="right">1.000</td>
<td align="right">100.0</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:t-democ">Table 2.2: </span>Frequency distribution of the democracy index in the country data.</caption>
<tbody>
<tr class="odd">
<td align="left">Democracy</td>
<td align="center"></td>
<td align="center"></td>
<td align="right"></td>
<td align="right">Cumulative</td>
</tr>
<tr class="even">
<td align="left">score</td>
<td align="center">Frequency</td>
<td align="center">Proportion</td>
<td align="right">%</td>
<td align="right">%</td>
</tr>
<tr class="odd">
<td align="left">0</td>
<td align="center">35</td>
<td align="center">0.226</td>
<td align="right">22.6</td>
<td align="right">22.6</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="center">12</td>
<td align="center">0.077</td>
<td align="right">7.7</td>
<td align="right">30.3</td>
</tr>
<tr class="odd">
<td align="left">2</td>
<td align="center">4</td>
<td align="center">0.026</td>
<td align="right">2.6</td>
<td align="right">32.9</td>
</tr>
<tr class="even">
<td align="left">3</td>
<td align="center">6</td>
<td align="center">0.039</td>
<td align="right">3.9</td>
<td align="right">36.8</td>
</tr>
<tr class="odd">
<td align="left">4</td>
<td align="center">5</td>
<td align="center">0.032</td>
<td align="right">3.2</td>
<td align="right">40.0</td>
</tr>
<tr class="even">
<td align="left">5</td>
<td align="center">5</td>
<td align="center">0.032</td>
<td align="right">3.2</td>
<td align="right">43.2</td>
</tr>
<tr class="odd">
<td align="left">6</td>
<td align="center">12</td>
<td align="center">0.077</td>
<td align="right">7.7</td>
<td align="right">50.9</td>
</tr>
<tr class="even">
<td align="left">7</td>
<td align="center">13</td>
<td align="center">0.084</td>
<td align="right">8.4</td>
<td align="right">59.3</td>
</tr>
<tr class="odd">
<td align="left">8</td>
<td align="center">16</td>
<td align="center">0.103</td>
<td align="right">10.3</td>
<td align="right">69.6</td>
</tr>
<tr class="even">
<td align="left">9</td>
<td align="center">15</td>
<td align="center">0.097</td>
<td align="right">9.7</td>
<td align="right">79.3</td>
</tr>
<tr class="odd">
<td align="left">10</td>
<td align="center">32</td>
<td align="center">0.206</td>
<td align="right">20.6</td>
<td align="right">99.9</td>
</tr>
<tr class="even">
<td align="left">Total</td>
<td align="center">155</td>
<td align="center">0.999</td>
<td align="right">99.9</td>
<td align="right"></td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:t-attitude">Table 2.3: </span>Frequency distribution of responses to a question on attitude towards income redistribution in the survey example.</caption>
<tbody>
<tr class="odd">
<td align="left">Response</td>
<td align="right">Frequency</td>
<td align="center">Proportion</td>
<td align="right">%</td>
<td align="right">Cumulative %</td>
</tr>
<tr class="even">
<td align="left">Agree strongly (1)</td>
<td align="right">366</td>
<td align="center">0.156</td>
<td align="right">15.6</td>
<td align="right">15.6</td>
</tr>
<tr class="odd">
<td align="left">Agree (2)</td>
<td align="right">1090</td>
<td align="center">0.465</td>
<td align="right">46.5</td>
<td align="right">62.1</td>
</tr>
<tr class="even">
<td align="left">Neither agree nor disagree (3)</td>
<td align="right">426</td>
<td align="center">0.182</td>
<td align="right">18.2</td>
<td align="right">80.3</td>
</tr>
<tr class="odd">
<td align="left">Disagree (4)</td>
<td align="right">387</td>
<td align="center">0.165</td>
<td align="right">16.5</td>
<td align="right">96.8</td>
</tr>
<tr class="even">
<td align="left">Disagree strongly (5)</td>
<td align="right">75</td>
<td align="center">0.032</td>
<td align="right">3.2</td>
<td align="right">100.0</td>
</tr>
<tr class="odd">
<td align="left">Total</td>
<td align="right">2344</td>
<td align="center">1.00</td>
<td align="right">100.0</td>
<td align="right"></td>
</tr>
</tbody>
</table>
<p>Each row of such a table corresponds to one possible value of a variable, and the second column shows the number of units with that value in the data. Thus there are 48 countries from Africa and 44 from Asia in the contry data set and 32 countries with the highest democracy score 10, and so on. Similarly, 366 respondents in the survey sample strongly agreed with the attitude question, and 75 strongly disagreed with it. These counts are also called <strong>frequencies</strong>, a distribution like this is a <strong>frequency distribution</strong>, and the table is also known as a <strong>frequency table</strong>. The sum of the frequencies, given on the line labelled “Total” in the tables, is the sample size <span class="math inline">\(n\)</span>, here 155 for the country data and 2344 for the survey data.</p>
<p>It is sometimes more convenient to consider relative values of the frequencies instead of the frequencies themselves. The <strong>relative frequency</strong> or <strong>proportion</strong> of a category of a variable is its frequency divided by the sample size. For example, the proportion of countries from Africa in the country data is <span class="math inline">\(48/155=0.310\)</span> (rounded to three decimal places). A close relative of the proportion is the <strong>percentage</strong>, which is simply proportion multiplied by a hundred; for example, 31% of the countries in the sample are from Africa. The sum of the proportions is one, and the sum of the percentages is one hundred (because of rounding error, the sum in a reported table may be very slightly different, as it is in Table <a href="c-descr1.html#tab:t-democ">2.2</a>).</p>
</div>
<div id="ss-descr1-1cat-charts" class="section level3">
<h3><span class="header-section-number">2.3.3</span> Graphical methods: Bar charts</h3>
<p>Graphical methods of describing data (<em>statistical graphics</em>) make use of our ability to process and interpret even very large amounts of visual information. The basic graph for summarising the sample distribution of a discrete variable is a <strong>bar chart</strong>. It is the graphical equivalent of a one-way table of frequencies.</p>
<p>Figures <a href="#fig:f-bars-region">2.1</a>, <a href="#fig:f-bars-democ">2.2</a> and <a href="#fig:f-bars-attitude">2.3</a> show the bar charts for region, democracy index and attitude, corresponding to the frequencies in Tables <a href="c-descr1.html#tab:t-region">2.1</a>, <a href="c-descr1.html#tab:t-democ">2.2</a> and <a href="c-descr1.html#tab:t-attitude">2.3</a>. Each bar corresponds to one category of the variable, and the height of the bar is proportional to the frequency of observations in that category. This visual cue allows us to make quick comparisons between the frequencies of different categories by comparing the heights of the bars.</p>
<p><img src="regions.png" alt=" Bar chart of regions in the country data." />{height=“9.5cm”}</p>
<p><img src="democ.png" alt=" Bar chart of the democracy index in the country data." />{height=“9.5cm”}</p>
<p><img src="bar_attitude.png" alt=" Bar chart of the attitude variable in the survey data example. Agreement with statement: ``The government should take measures to reduce differences in income levels’’. European Social Survey, Round 5 (2010), UK respondents only." />{height=“8cm”}</p>
<p>Some guidelines for drawing bar charts are:</p>
<ul>
<li><p>The heights of the bars may represent frequencies, proportions or percentages. This only changes the units on the vertical axis but not the relative heights of the bars. The shape of the graph will be the same in each case. In Figure <a href="#fig:f-bars-region">2.1</a>, the units are frequencies, while in Figures <a href="#fig:f-bars-democ">2.2</a> and <a href="#fig:f-bars-attitude">2.3</a> they are percentages.</p></li>
<li><p>The bars do not touch each other, to highlight the discrete nature of the variable.</p></li>
<li><p>The bars <em>must</em> start at zero. It they do not, visual comparisons between their heights are distorted and the graph becomes useless.</p></li>
<li><p>If the variable is ordinal, the bars must be in the natural order of the categories, as in Figures <a href="#fig:f-bars-democ">2.2</a> and <a href="#fig:f-bars-attitude">2.3</a>. If the variable is nominal, the order is arbitrary. Often it makes sense to order the categories from largest (i.e. the one with the largest frequency) to the smallest, possibly leaving any “Others” category last. In Figure <a href="#fig:f-bars-region">2.1</a>, the frequency ordering would swap Northern America and Oceania, but it seems more natural to keep Northern and Latin America next to each other.</p></li>
</ul>
<p>A bar chart is a relatively unexciting statistical graphic in that it does not convey very much visual information. For nominal variables, in particular, the corresponding table is often just as easy to understand and takes less space. For ordinal variables, the bar chart has the additional advantage that its shape shows how the frequencies vary across the ordering of the categories. For example, Figure <a href="#fig:f-bars-democ">2.2</a> quite effectively conveys the information that the most common values of the democracy index are the extreme scores 0 and 10.</p>
<p>Sometimes you may see graphs which look like bar charts of this kind, but which actually show the values of a single variable for some units rather than frequncies or percentages. For example, a report on the economies of East Asia might show a chart of GDP per capita for Japan, China, South Korea and North Korea, with one bar for each country, and their heights proportional to 28.2, 5.0, 17.8 and 1.3 respectively (c.f. the data in Table <a href="c-descr1.html#tab:t-countrydata">2.14</a>). The basic idea of such graphs is the same as that of standard bar charts. However, they are not particularly useful as descriptive statistics, since they simply display values in the original data without any summarization or simplification.</p>
</div>
<div id="ss-descr1-1cat-descriptives" class="section level3">
<h3><span class="header-section-number">2.3.4</span> Simple descriptive statistics</h3>
<p>Instead of the whole sample distribution, we may want to summarise only some individual aspects of it, such as its central tendency or variation. Descriptive statistics that are used for this purpose are broadly similar for both discrete and continuous variables, so they will be discussed together for both in Section <a href="c-descr1.html#s-descr1-nums">2.6</a>.</p>
</div>
</div>
<div id="s-descr1-2cat" class="section level2">
<h2><span class="header-section-number">2.4</span> Two categorical variables</h2>
<div id="ss-descr1-2cat-tables" class="section level3">
<h3><span class="header-section-number">2.4.1</span> Two-way contingency tables</h3>
<p>The next task we consider is how to describe the sample distributions of two categorical variables together, and in so doing also summarise the association between these variables. The key tool is a table which shows the <strong>crosstabulation</strong> of the frequencies of the variables. This is also known as a <strong>contingency table</strong>. Table <a href="c-descr1.html#tab:t-sex-attitude">2.4</a> shows such a table for the respondents’ sex and attitude in our survey example. We use it to introduce the basic structure and terminology of contingency tables:</p>
<table style="width:98%;">
<caption><span id="tab:t-sex-attitude">Table 2.4: </span><em>``The government should take measures to reduce differences in income levels’’</em>: Two-way table of frequencies of respondents in the survey example, by sex and attitude towards income redistribution. Data: European Social Survey, Round 5, 2010, UK respondents only.</caption>
<colgroup>
<col width="26%" />
<col width="16%" />
<col width="8%" />
<col width="16%" />
<col width="11%" />
<col width="11%" />
<col width="7%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><br />
Sex</td>
<td align="center">Agree strongly</td>
<td align="center"><br />
Agree</td>
<td align="center">Neither agree nor disagree</td>
<td align="center"><br />
Disagree</td>
<td align="center">Disagree strongly</td>
<td align="right"><br />
Total</td>
</tr>
<tr class="even">
<td align="left">Male</td>
<td align="center">160</td>
<td align="center">439</td>
<td align="center">187</td>
<td align="center">200</td>
<td align="center">41</td>
<td align="right">1027</td>
</tr>
<tr class="odd">
<td align="left">Female</td>
<td align="center">206</td>
<td align="center">651</td>
<td align="center">239</td>
<td align="center">187</td>
<td align="center">34</td>
<td align="right">1317</td>
</tr>
<tr class="even">
<td align="left">Total</td>
<td align="center">366</td>
<td align="center">1090</td>
<td align="center">426</td>
<td align="center">387</td>
<td align="center">75</td>
<td align="right">2344</td>
</tr>
</tbody>
</table>
<ul>
<li><p>Because a table like <a href="c-descr1.html#tab:t-sex-attitude">2.4</a> summarizes the values of two variables, it is known as a <strong>two-way</strong> contingency table. Similarly, the tables of single variables introduced in Section <a href="c-descr1.html#ss-descr1-1cat-tables">2.3.2</a> are <em>one-way</em> tables. It is also possible to construct tables involving more than two variables, i.e. three-way tables, four-way tables, and so on. These are discussed in Chapter <a href="c-3waytables.html#c-3waytables">9</a>.</p></li>
<li><p>The variables in a contingency table may ordinal or nominal (including dichotomous). Often an ordinal variable is derived by grouping an originally continuous, interval-level variable, a practice which is discussed further in Section <a href="c-descr1.html#s-descr1-1cont">2.5</a>.</p></li>
<li><p>The horizontal divisions of a table (e.g. the lines corresponding to the two sexes in Table <a href="c-descr1.html#tab:t-sex-attitude">2.4</a>) are its <strong>rows</strong>, and the vertical divisions (e.g. the survey responses in Table <a href="c-descr1.html#tab:t-sex-attitude">2.4</a>) are its <strong>columns</strong>.</p></li>
<li><p>The size of a contingency table is stated in terms of the numbers of its rows and columns. For example, Table <a href="c-descr1.html#tab:t-sex-attitude">2.4</a> is a <span class="math inline">\(2\times 5\)</span> (pronounced “two-by-five”) table, because it has two rows and five columns. This notation may also be used symbolically, so that we may refer generically to <span class="math inline">\(R\times C\)</span> tables which have some (unspecified) number of <span class="math inline">\(R\)</span> rows and <span class="math inline">\(C\)</span> columns. The smallest two-way table is thus a <span class="math inline">\(2\times 2\)</span> table, where both variables are dichotomous.</p></li>
<li><p>The intersection of a row and a column is a <strong>cell</strong> of the table. The basic two-way contingency table shows in each cell the number (frequency) of units in the data set with the corresponding values of the row variable and the column variable. For example, Table <a href="c-descr1.html#tab:t-sex-attitude">2.4</a> shows that there were 160 male respondents who strongly agreed with the statement, and 239 female respondents who neither agreed nor disagreed with it. These frequencies are also known as <strong>cell counts</strong>.</p></li>
<li><p>The row and column labelled “Total” in Table <a href="c-descr1.html#tab:t-sex-attitude">2.4</a> are known as the <strong>margins</strong> of the table. They show the frequencies of the values of the row and the column variable separately, summing the frequencies over the categories of the other variable. For example, the table shows that there were overall 1027 (<span class="math inline">\(=160+439+187+200+41\)</span>) male respondents, and that overall 75 (<span class="math inline">\(=41+34\)</span>) respondents strongly disagreed with the statement. In other words, the margins are <em>one-way</em> tables of the frequencies of each of the two variables, so for example the frequencies on the margin for attitude in Table <a href="c-descr1.html#tab:t-sex-attitude">2.4</a> are the same as the ones in the one-way table for this variable shown in Table <a href="c-descr1.html#tab:t-attitude">2.3</a>. The distributions described by the margins are known as the <strong>marginal distributions</strong> of the row and column variables. In contrast, the frequencies in the internal cells of the table, which show how many units have each possible <em>combination</em> of the row and column variables, describe the <strong>joint distribution</strong> of the two variables.</p></li>
<li><p>The number in the bottom right-hand corner of the table is the sum of all of the frequencies, i.e. the total sample size <span class="math inline">\(n\)</span>.</p></li>
</ul>
<p>In addition to frequencies, it is often convenient to display proportions or percentages. Dividing the frequencies by the sample size gives overall proportions and (multiplying by a hundred) percentages. This is illustrated in Table <a href="c-descr1.html#tab:t-sex-attitude-pr">2.5</a>, which shows the overall proportions, obtained by dividing the frequencies in Table <a href="c-descr1.html#tab:t-sex-attitude">2.4</a> by <span class="math inline">\(n=2344\)</span>. For example, out of all these respondents, the proportion of 0.102 (<span class="math inline">\(=239/2344\)</span>) were women who neither agreed nor disagreed with the statement. The proportions are also shown for the marginal distributions: for example, 15.6% (i.e. the proportion <span class="math inline">\(0.156=366/2344\)</span>) of the respondents strongly agreed with the statement. The sum of the proportions over all the cells is 1, as shown in the bottom right corner of the table.</p>
<table style="width:98%;">
<caption><span id="tab:t-sex-attitude-pr">Table 2.5: </span><em>``The government should take measures to reduce differences in income levels’’</em>: Two-way table of joint proportions of respondents in the survey example, with each combination of sex and attitude towards income redistribution. Data: European Social Survey, Round 5, 2010, UK respondents only.</caption>
<colgroup>
<col width="17%" />
<col width="18%" />
<col width="9%" />
<col width="18%" />
<col width="12%" />
<col width="12%" />
<col width="8%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><br />
Sex</td>
<td align="center">Agree strongly</td>
<td align="center"><br />
Agree</td>
<td align="center">Neither agree nor disagree</td>
<td align="center"><br />
Disagree</td>
<td align="center">Disagree strongly</td>
<td align="center"><br />
Total</td>
</tr>
<tr class="even">
<td align="left">Male</td>
<td align="center">0.068</td>
<td align="center">0.187</td>
<td align="center">0.080</td>
<td align="center">0.085</td>
<td align="center">0.017</td>
<td align="center">0.438</td>
</tr>
<tr class="odd">
<td align="left">Female</td>
<td align="center">0.088</td>
<td align="center">0.278</td>
<td align="center">0.102</td>
<td align="center">0.080</td>
<td align="center">0.015</td>
<td align="center">0.562</td>
</tr>
<tr class="even">
<td align="left">Total</td>
<td align="center">0.156</td>
<td align="center">0.465</td>
<td align="center">0.182</td>
<td align="center">0.165</td>
<td align="center">0.032</td>
<td align="center">1.000</td>
</tr>
</tbody>
</table>
</div>
<div id="ss-descr1-2cat-cond" class="section level3">
<h3><span class="header-section-number">2.4.2</span> Conditional proportions</h3>
<p>A two-way contingency table is symmetric in that it does not distinguish between explanatory and response variables. In many applications, however, this distinction is useful for interpretation. In our example, for instance, it is natural to treat sex as the explanatory variable and attitude towards income redistribution as the response response, and so to focus the interpretation on how attitude may depend on sex.</p>
<p>The overall proportions are in such cases not the most relevant quantities for interpretation of a table. Instead, we typically calculate proportions within each category of the row variable or the column variable, i.e. the <strong>conditional proportions</strong> of one variable given the other. The numbers in brackets in Table <a href="c-descr1.html#tab:t-sex-attitude-row">2.6</a> show these proportions calculated for each <em>row</em> of Table <a href="c-descr1.html#tab:t-sex-attitude">2.4</a> (Table <a href="c-descr1.html#tab:t-sex-attitude-row">2.6</a> also includes the actual frequencies; it is advisable to include them even when conditional proportions are of most interest, to show the numbers on which the proportions are based). In other words, these are the conditional proportions of attitude towards income redistribution given sex, i.e. separately for men and women. For example, the number 0.156 in the top left-hand corner of Table <a href="c-descr1.html#tab:t-sex-attitude-row">2.6</a> is obtained by dividing the number of male respondents who agreed strongly with the statement (160) by the total number of male respondents (1027). Thus 15.6% of the men strongly agreed, and for example 2.6% of women strongly disagreed with the statement. The (1.0) in the last column of the table indicate that the proportions sum to 1 along each row, to remind us that the conditional proportions have been calculated within the rows. The bracketed proportions in the ‘Total’ row are the proportions of the <em>marginal</em> distribution of the attitude variable, so they are the same as the proportions in the ‘Total’ row of Table <a href="c-descr1.html#tab:t-sex-attitude-pr">2.5</a>.</p>
<table style="width:98%;">
<caption><span id="tab:t-sex-attitude-row">Table 2.6: </span><em>``The government should take measures to reduce differences in income levels’’</em>: Two-way table of frequencies of respondents in the survey example, by sex and attitude towards income redistribution. The numbers in brackets are proportions within the rows, i.e. conditional proportions of attitude given sex. Data: European Social Survey, Round 5, 2010, UK respondents only.</caption>
<colgroup>
<col width="16%" />
<col width="18%" />
<col width="11%" />
<col width="18%" />
<col width="12%" />
<col width="12%" />
<col width="8%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><br />
Sex</td>
<td align="center">Agree strongly</td>
<td align="center"><br />
Agree</td>
<td align="center">Neither agree nor disagree</td>
<td align="center"><br />
Disagree</td>
<td align="center">Disagree strongly</td>
<td align="center"><br />
Total</td>
</tr>
<tr class="even">
<td align="left">Male</td>
<td align="center">160</td>
<td align="center">439</td>
<td align="center">187</td>
<td align="center">200</td>
<td align="center">41</td>
<td align="center">1027</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="center">(0.156)</td>
<td align="center">(0.428)</td>
<td align="center">(0.182)</td>
<td align="center">(0.195)</td>
<td align="center">(0.040)</td>
<td align="center">(1.0)</td>
</tr>
<tr class="even">
<td align="left">Female</td>
<td align="center">206</td>
<td align="center">651</td>
<td align="center">239</td>
<td align="center">187</td>
<td align="center">34</td>
<td align="center">1317</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="center">(0.156)</td>
<td align="center">(0.494)</td>
<td align="center">(0.182)</td>
<td align="center">(0.142)</td>
<td align="center">(0.026)</td>
<td align="center">(1.0)</td>
</tr>
<tr class="even">
<td align="left">Total</td>
<td align="center">366</td>
<td align="center">1090</td>
<td align="center">426</td>
<td align="center">387</td>
<td align="center">75</td>
<td align="center">2344</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="center">(0.156)</td>
<td align="center">(0.465)</td>
<td align="center">(0.182)</td>
<td align="center">(0.165)</td>
<td align="center">(0.032)</td>
<td align="center">(1.0)</td>
</tr>
</tbody>
</table>
<p>We could also have calculated conditional proportions within the <em>columns</em>, i.e. for sex given attitude. For example, the proportion <span class="math inline">\(0.563=206/366\)</span> of all respondents who strongly agreed with the statement are women. These, however, seem less interesting, because it seems more natural to examine how attitude varies by sex rather than how sex varies by attitude. In general, for any two-way table we can calculate conditional proportions for both the rows and the columns, but typically only one of them is used for interpretation.</p>
</div>
<div id="ss-descr1-2cat-assoc" class="section level3">
<h3><span class="header-section-number">2.4.3</span> Conditional distributions and associations</h3>
<p>Suppose that we regard one variable in a two-way table as the explanatory variable (let us denote it by <span class="math inline">\(X\)</span>) and the other variable as the response variable (<span class="math inline">\(Y\)</span>). In our survey example, sex is thus <span class="math inline">\(X\)</span> and attitude is <span class="math inline">\(Y\)</span>. Here the dichotomous <span class="math inline">\(X\)</span> divides the full sample into two groups, identified by the observed value of <span class="math inline">\(X\)</span> — men and women. We may then think of these two groups as two separate samples, and consider statistical quantities separately for each of them. In particular, in Table <a href="c-descr1.html#tab:t-sex-attitude-row">2.6</a> we calculated conditional proportions for <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span>, i.e. for attitude given sex. These proportions describe two distinct sample distributions of <span class="math inline">\(Y\)</span>, one for men and one for women. They are examples of <em>conditional distributions</em>:</p>
<ul>
<li>The <strong>conditional distribution</strong> of a variable <span class="math inline">\(Y\)</span> given another variable <span class="math inline">\(X\)</span> is the distribution of <span class="math inline">\(Y\)</span> among those units which have a particular value of <span class="math inline">\(X\)</span>.</li>
</ul>
<p>This concept is not limited to two-way tables but extends also to other kinds of variables and distributions that are discussed later in this coursepack. Both the response variable <span class="math inline">\(Y\)</span> and the explanatory variable <span class="math inline">\(X\)</span> may be continuous as well as discrete, and can have any number of values. In all such cases there is a separate conditional distribution for <span class="math inline">\(Y\)</span> for each possible value of <span class="math inline">\(X\)</span>. A particular one of these distributions is sometimes referred to more explicitly as the conditional distribution of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X=x\)</span>, where the “<span class="math inline">\(X=x\)</span>” indicates that <span class="math inline">\(X\)</span> is considered at a particular value <span class="math inline">\(x\)</span> (as in “the distribution of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X=2\)</span>”, say).</p>
<p>Conditional distributions of one variable given another allow us to define and describe associations between the variables. The informal definition in Section <a href="c-intro.html#ss-intro-def-assoc">1.2.4</a> stated that there is an association between two variables if knowing the value of one of them will help to predict the value of the other. We can now give a more precise definition:</p>
<ul>
<li>There is an <strong>association</strong> between variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> if the conditional distribution of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span> is different for different values of <span class="math inline">\(X\)</span>.</li>
</ul>
<p>This definition coincides with the more informal one. If the conditional distribution of <span class="math inline">\(Y\)</span> varies with <span class="math inline">\(X\)</span> and if we know <span class="math inline">\(X\)</span>, it is best to predict <span class="math inline">\(Y\)</span> from its conditional distribution given the known value of <span class="math inline">\(X\)</span>. This will indeed work better than predicting <span class="math inline">\(Y\)</span> without using information on <span class="math inline">\(X\)</span>, i.e. from the marginal distribution of <span class="math inline">\(Y\)</span>. Prediction based on the conditional distribution would still be subject to error, because in most cases <span class="math inline">\(X\)</span> does not predict <span class="math inline">\(Y\)</span> perfectly. In other words, the definition of an association considered here is <em>statistical</em> (or <em>probabilistic</em>) rather than <em>deterministic</em>. In our example a deterministic association would mean that there is one response given by all the men and one response (possibly different from the men’s) given by all the women. This is of course not the case here nor in most other applications in the social sciences. It is thus crucially important that we have the tools also to analyse statistical associations.</p>
<p>In our example, sex and attitude are associated if men and women differ in their attitudes toward income redistribution. Previous studies suggest that such an association exists, and that it takes the form that women tend to have higher levels of support than men for redistribution.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> As possible explanations for this pattern, both structural reasons (women tend to have lower incomes than men and to rely more on welfare state support) and cultural or psychological ones (women are more likely than men to adopt social values of equality and caring) have been suggested.</p>
</div>
<div id="ss-descr1-2cat-descr" class="section level3">
<h3><span class="header-section-number">2.4.4</span> Describing an association using conditional proportions</h3>
<p>Two variables presented in a contingency table are associated in the sample if the conditional distributions of one of them vary across the values of the other. This is the case in our data set: for example, 4.0% of men but 2.6% of women strongly disagree with the statement. There is thus some association between sex and attitude in this sample. This much is easy to conclude. What requires a little more work is a more detailed description of the pattern and strength of the association, i.e. how and where the conditional distributions differ from each other.</p>
<p>The most general way of summarising associations in a contingency table is by comparing the conditional proportions of the same level of the response given different levels of the explanatory variable. There is no simple formula for how this should be done, so you should use your common sense to present comparisons which give a good summary of the patterns across the table. Unless both variables in the table are dichotomous, several different comparisons may be needed, and may not all display similar patterns. For example, in Table <a href="c-descr1.html#tab:t-sex-attitude-row">2.6</a> the same proportion (0.156, or 15.6%) of both men and women strongly agree with the statement, whereas the proportion who respond “Agree” is higher for women (49.4%) than for men (42.8%).</p>
<p>When the response variable is ordinal, it is often more illuminating to focus on comparisons of <em>cumulative</em> proportions which add up conditional proportions over two or more adjacent categories. For instance, the combined proportion of respondents who either strongly agree or agree with the statement is a useful summary of the general level of agreement among the respondents. In our example this is 58.4% (<span class="math inline">\(=15.5\%+42.8\%\)</span>) for men but 65.0% for women.</p>
<p>A comparison between two proportions may be further distilled into a single number by reporting the <em>difference</em> or <em>ratio</em> between them. For example, for the proportions of agreeing or strongly agreeing above, the difference is <span class="math inline">\(0.650-0.584=0.066\)</span>, so the proportion is 0.066 (i.e. 6.6 percentage points) higher for women than for men. The ratio of these proportions is <span class="math inline">\(0.650/0.584=1.11\)</span>, so the proportion for women is 1.11 times the proportion for men (i.e. 11% higher). Both of these indicate that in this sample women were more likely to agree or strongly agree with the statement than were men. In a particular application we might report a difference or a ratio like this, depending on which of them was considered more relevant or easily understandable. Other summaries are also possible; for example, on MY452 we will discuss a measure called the <em>odds ratio</em>, which turns out to be convenient for more general methods of analysing associations involving categorical variables.</p>
<p>The broad conclusion in the example is that there is an association between sex and attitude in these data from the European Social Survey, and that it is of the kind suggested by existing literature. A larger proportion of women than of men indicate agreement with the statement that the government should take measures to reduce income differences, and conversely larger proportion of men disagree with it (e.g. 23.5% of men but only 16.8% of women disagree or strongly disagree). Thus in this sample women do indeed demonstrate somewhat higher levels of support for income redistribution. Whether these differences also warrant a generalisation of the conclusions to people outside the sample is a question which we will take up in Chapters <a href="c-samples.html#c-samples">3</a> and <a href="c-tables.html#c-tables">4</a>.</p>
</div>
<div id="ss-descr1-2cat-gamma" class="section level3">
<h3><span class="header-section-number">2.4.5</span> A measure of association for ordinal variables</h3>
<p>In the previous example the explanatory variable (sex) had 2 categories and the response variable (attitude) had 5. A full examination of the individual conditional distributions of attitude given sex then involved comparisons of five pairs of proportions, one for each level of the attitude variable. This number gets larger still if the explanatory variable also has several levels, as in the following example:</p>
<p><em>Example: Importance of short-term gains for investors</em></p>
<p>Information on the behaviour and expectations of individual investors was collected by sending a questionnaire to a sample of customers of a U.S. brokerage house.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> One of the questions asked the respondents to state how much importance they placed on quick profits (short-term gains) as an objective when they invested money. The responses were recorded in four categories as “Irrelevant”, “Slightly important”, “Important” or “Very important”. Table <a href="c-descr1.html#tab:t-investors">2.7</a> shows the crosstabulation of this variable with the age of the respondent in four age groups.</p>
<table style="width:98%;">
<caption><span id="tab:t-investors">Table 2.7: </span>Importance of short-term gains: Frequencies of respondents in the investment example, by age group and attitude towards short-term gains as investment goal. Conditional proportions of attitude given age group are shown in brackets. The value of the <span class="math inline">\(\gamma\)</span> measure of association is <span class="math inline">\(-0.377\)</span>.</caption>
<colgroup>
<col width="12%" />
<col width="47%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="6%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><br />
Age group</td>
<td align="right"><br />
Irrelevant</td>
<td align="right">Slightly important</td>
<td align="right"><br />
Important</td>
<td align="right">Very important</td>
<td align="right"><br />
Total</td>
</tr>
<tr class="even">
<td align="left">Under 45</td>
<td align="right">37</td>
<td align="right">45</td>
<td align="right">38</td>
<td align="right">26</td>
<td align="right">146</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="right">(0.253)</td>
<td align="right">(0.308)</td>
<td align="right">(0.260)</td>
<td align="right">(0.178)</td>
<td align="right">(1.00)</td>
</tr>
<tr class="even">
<td align="left">45–54</td>
<td align="right">111</td>
<td align="right">77</td>
<td align="right">57</td>
<td align="right">37</td>
<td align="right">282</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="right">(0.394)</td>
<td align="right">(0.273)</td>
<td align="right">(0.202)</td>
<td align="right">(0.131)</td>
<td align="right">(1.00)</td>
</tr>
<tr class="even">
<td align="left">55–64</td>
<td align="right">153</td>
<td align="right">49</td>
<td align="right">31</td>
<td align="right">20</td>
<td align="right">253</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="right">(0.605)</td>
<td align="right">(0.194)</td>
<td align="right">(0.123)</td>
<td align="right">(0.079)</td>
<td align="right">(1.00)</td>
</tr>
<tr class="even">
<td align="left">65 and over</td>
<td align="right">193</td>
<td align="right">64</td>
<td align="right">19</td>
<td align="right">15</td>
<td align="right">291</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="right">(0.663)</td>
<td align="right">(0.220)</td>
<td align="right">(0.065)</td>
<td align="right">(0.052)</td>
<td align="right">(1.00)</td>
</tr>
<tr class="even">
<td align="left">Total</td>
<td align="right">494</td>
<td align="right">235</td>
<td align="right">145</td>
<td align="right">98</td>
<td align="right">972</td>
</tr>
</tbody>
</table>
<p>Here there are four conditional distributions, one for each age group, and each of them is described by four proportions of different levels of attitude. There are then many possible comparisons of the kind discussed above. For example, we might want to compare the proportions of respondents who consider short-term gains irrelevant between the oldest and the youngest age group, the proportions for whom such gains are very important between these two groups, or, in general, the proportions in any category of the response variable between any two age groups.</p>
<p>Although pairwise comparisons like this are important and informative, they can clearly become cumbersome when the number of possible comparisons is large. A potentially attractive alternative is then to try to summarise the strength of the association between the variables in a single number, a <strong>measure of association</strong> of some kind. There are many such measures for two-way contingency tables, labelled with a range of Greek and Roman letters (e.g. <span class="math inline">\(\phi\)</span>, <span class="math inline">\(\lambda\)</span>, <span class="math inline">\(\gamma\)</span>, <span class="math inline">\(\rho\)</span>, <span class="math inline">\(\tau\)</span>, V, Q, U and d). The most useful of them are designed for tables where both of the variables are measured at the ordinal level, as is the case in Table <a href="c-descr1.html#tab:t-investors">2.7</a>. The ordering of the categories can then be exploited to capture the strength of the association in a single measure. This is not possible when at least one of the variables is measured at the nominal level, as any attempt to reduce the patterns of the conditional probabilities into one number will then inevitably obscure much of the information in the table. It is better to avoid measures of association defined for nominal variables, and to describe their associations only through comparisons of conditional probabilities as described in the previous section.</p>
<p>Here we will discuss only one measure of association for two-way tables of ordinal variables. It is known as <span class="math inline">\(\gamma\)</span> (“gamma”). It characterises one possible general pattern of association between two ordinal variables, namely the extent to which high values of one variable tend to be associated with high or low values of the other variable. Here speaking of “low” and “high” values, or of “increasing” or “decreasing” them, is meaningful when the variables are ordinal. For example, in Table <a href="c-descr1.html#tab:t-investors">2.7</a> the categories corresponding to the bottom rows and right-most columns are in an obvious sense “high” values of age and importance respectively.</p>
<p>Consider the conditional proportions of importance given age group shown in Table <a href="c-descr1.html#tab:t-investors">2.7</a>. It is clear that, for example, the proportion of respondents for whom short-term gains are very important is highest in the youngest, and lowest in the oldest age group. Similarly, the proportion of respondents for whom such gains are irrelevant increases consistently from the youngest to the oldest group. In other words, respondents with <em>high</em> values of the explanatory variable (age group) tend to have <em>low</em> values the response variable (importance of short-term gains). Such an association is said to be <em>negative</em>. A <em>positive</em> association would be seen in a table where high values of one variable were associated with high values of the other.</p>
<p>Measures of association for summarising such patterns are typically based on the numbers of concordant and discordant pairs of observations. Suppose we compare two units classified according to the two variables in the table. These units form a <em>concordant pair</em> if one of them has a higher value of both variables than the other. For example, consider two respondents in Table <a href="c-descr1.html#tab:t-investors">2.7</a>, one with values (Under 45; Irrelevant) and the other with (45–54; Important). This is a concordant pair, because the second respondent has both a higher value of age group (45–54 vs. Under 45) and a higher value of the importance variable (Important vs. Irrelevant) than the first respondent. In contrast, in a <em>discordant pair</em> one unit has a higher value of one variable but a lower value of the other variable than the other unit. For example, a pair of respondents with values (45–54; Very important) and (55–64; Irrelevant) is discordant, because the latter has a higher value of age group but a lower value of the importance variable than the former. Pairs of units with the same value of one or both of the variables are known as <em>tied</em> pairs. They are not used in the calculations discussed below.</p>
The <span class="math inline">\(\gamma\)</span> measure of association is defined as
\begin{equation}\gamma=\frac{C-D}{C+D}
\label{eq:gamma}\end{equation}
<p>where <span class="math inline">\(C\)</span> is the total number of concordant pairs in the table, and <span class="math inline">\(D\)</span> is the number of discordant pairs. For Table <a href="c-descr1.html#tab:t-investors">2.7</a>, the value of this is <span class="math inline">\(\gamma=-0.377\)</span>.</p>
<p>Calculation of <span class="math inline">\(C\)</span> and <span class="math inline">\(D\)</span> is straightforward but tedious and uninteresting, and can be left to a computer. Remembering the exact form of (\ref{eq:gamma}) is also not crucial. More important than the formula of <span class="math inline">\(\gamma\)</span> (or any other measure of association) is its interpretation. This can be considered on several levels of specificity, which are discussed separately below. The discussion is relatively detailed, as these considerations are relevant and useful not only for <span class="math inline">\(\gamma\)</span>, but also for all other measures of association in statistics.</p>
<p>The <strong>sign</strong> of the statistic: It can be seen from (\ref{eq:gamma}) that <span class="math inline">\(\gamma\)</span> is positive (greater than zero) when there are more concordant pairs than discordant ones (i.e. <span class="math inline">\(C&gt;D\)</span>), and negative when there are more discordant than concordant pairs (<span class="math inline">\(C&lt;D\)</span>). This also implies that <span class="math inline">\(\gamma\)</span> will be positive when the association is positive in the sense discussed above, and negative when the association is negative. A value of <span class="math inline">\(\gamma=0\)</span> indicates a complete lack of association of this kind. In Table <a href="c-descr1.html#tab:t-investors">2.7</a> we have <span class="math inline">\(\gamma=-0.377\)</span>, indicating a negative association. This agrees with the conclusion obtained informally above.</p>
<p>The <strong>extreme values</strong> of the statistic: Clearly <span class="math inline">\(\gamma=1\)</span> if there are no discordant pairs (<span class="math inline">\(D=0\)</span>), and <span class="math inline">\(\gamma=-1\)</span> if there are no concordant pairs (<span class="math inline">\(C=0\)</span>). The values <span class="math inline">\(\gamma=-1\)</span> and <span class="math inline">\(\gamma=1\)</span> are the smallest and largest possible values of <span class="math inline">\(\gamma\)</span>, and indicate the strongest possible levels of negative and positive association respectively. More generally, the closer <span class="math inline">\(\gamma\)</span> is to <span class="math inline">\(-1\)</span> or 1, the stronger is the (negative or positive) association.</p>
<p>The <strong>formal interpretation</strong> of the statistic: This refers to any way of interpreting the value more understandably than just vaguely as a measure of “strength of association”. Most often, such an intepretation is expressed as a <em>proportion</em> of some kind. For <span class="math inline">\(\gamma\)</span>, this is done using a principle known as <strong>Proportional reduction of error</strong> (PRE). Because the PRE idea is also used to interpret many other measures of association in statistics, we will first describe it in general terms which are not limited to <span class="math inline">\(\gamma\)</span>.</p>
<p>Suppose we consider an explanatory variable <span class="math inline">\(X\)</span> and a response variable <span class="math inline">\(Y\)</span>, and want to make predictions of the values of <span class="math inline">\(Y\)</span> in a data set. This is done twice, first in a way which makes no use of <span class="math inline">\(X\)</span>, and then in a way which predicts the value of <span class="math inline">\(Y\)</span> for each unit using information on the corresponding value of <span class="math inline">\(X\)</span> and on the strength and direction of the association between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Recalling the connection between association and prediction, it is clear that the second approach should result in better predictions if the two variables are associated. The comparison also reflects the <em>strength</em> of the association: the stronger it is, the bigger is the improvement in prediction gained by utilising information on <span class="math inline">\(X\)</span>.</p>
A PRE measure describes the size of this improvement. Suppose that the magnitude or number of errors made in predicting the values of <span class="math inline">\(Y\)</span> in a data set using the first scheme, i.e. ignoring information on <span class="math inline">\(X\)</span>, is somehow measured by a single number <span class="math inline">\(E_{1}\)</span>, and that <span class="math inline">\(E_{2}\)</span> is the same measure of errors for the second prediction scheme which makes use of <span class="math inline">\(X\)</span>. The difference <span class="math inline">\(E_{1}-E_{2}\)</span> is thus the improvement in prediction achieved by the second scheme over the first. A PRE measure of association is the ratio
\begin{equation}\text{PRE}= \frac{E_{1}-E_{2}}{E_{1}},
\label{eq:PRE}\end{equation}
<p>i.e. the improvement in predictions as a <em>proportion</em> of the number of errors <span class="math inline">\(E_{1}\)</span> under the first scheme. This formulation is convenient for interpretation, because a proportion is easily understandable even if <span class="math inline">\(E_{1}\)</span> and <span class="math inline">\(E_{2}\)</span> themselves are expressed in some unfamiliar units. The smallest possible value of (\ref{eq:PRE}) is clearly 0, obtained when <span class="math inline">\(E_{2}=E_{1}\)</span>, i.e. when using information on <span class="math inline">\(X\)</span> gives no improvement in predictions. The largest possible value of PRE is 1, obtained when <span class="math inline">\(E_{2}=0\)</span>, i.e. when <span class="math inline">\(Y\)</span> can be predicted perfectly from <span class="math inline">\(X\)</span>. The values 0 and 1 indicate no association and perfect association respectively.</p>
<p>The <span class="math inline">\(\gamma\)</span> statistic is a PRE measure, although with a somewhat convoluted explanation. Suppose that we consider a pair of observations which is known to be either concordant or discordant (the PRE interpretation of <span class="math inline">\(\gamma\)</span> ignores tied observations). One of the two observations thus has a higher value of <span class="math inline">\(X\)</span> than the other. For example, suppose that we consider two respondents in Table <a href="c-descr1.html#tab:t-investors">2.7</a> from different age groups. We are then asked to predict the <em>order</em> of the values of <span class="math inline">\(Y\)</span>, i.e. which of the two units has the higher value of <span class="math inline">\(Y\)</span>. In the example of Table <a href="c-descr1.html#tab:t-investors">2.7</a>, this means predicting whether the older respondent places a higher or lower level of importance on short-term gains than the younger respondent. Two sets of predictions are again compared. The first approach makes the prediction at random and with equal probabilities, essentially tossing a coin to guess whether the observation with the higher value of <span class="math inline">\(X\)</span> has the higher or lower value of <span class="math inline">\(Y\)</span>. The second prediction makes use of information on the direction of the association between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. If the association is known to be negative (i.e. there are more discordant than concordant pairs), every pair is predicted to be discordant; if it is positive, every pair is predicted to be concordant. For example, in Table <a href="c-descr1.html#tab:t-investors">2.7</a> the association is negative, so we would always predict that the older of two respondents places a lower value of importance on short-term gains.</p>
<p>If these predictions are repeated for every non-tied pair in the table, the expected number of incorrect predictions under the first scheme is <span class="math inline">\(E_{1}=(C+D)/2\)</span>. Under the second scheme it is <span class="math inline">\(E_{2}=D\)</span> if the association is positive and <span class="math inline">\(E_{2}=C\)</span> if it is negative. Substituting these into the general formula (\ref{eq:PRE}) shows that the <span class="math inline">\(\gamma\)</span> statistic (\ref{eq:gamma}) is of the PRE form when <span class="math inline">\(\gamma\)</span> is positive; when it is negative, the absolute value of <span class="math inline">\(\gamma\)</span> (i.e. its value with the minus sign omitted) is a PRE measure, and the negative sign of <span class="math inline">\(\gamma\)</span> indicates that the association is in the negative direction. In our example <span class="math inline">\(\gamma=-0.377\)</span>, so age and attitude are negatively associated. Its absolute value <span class="math inline">\(0.377\)</span> shows that we will make 37.7% fewer errors if we predict for every non-tied pair that the older respondent places less importance on short-term gains, compared to predictions made by tossing a coin for each pair.</p>
<p>The final property of interest is the <strong>substantive interpretation</strong> of the strength of association indicated by <span class="math inline">\(\gamma\)</span> for a particular table. For example, should <span class="math inline">\(\gamma=-0.377\)</span> for Table <a href="c-descr1.html#tab:t-investors">2.7</a> be regarded as evidence of weak, moderate or strong negative association between age and attitude? Although this is usually the most (or only) interesting part of the interpretation, it is also the most difficult, and one to which a statistician’s response is likely to be a firm “it depends”. This is because the strength of associations we may expect to observe depends on the variables under consideration: a <span class="math inline">\(\gamma\)</span> of 0.5, say, might be commonplace for some types of variables but never observed for others. Considerations of the magnitude of <span class="math inline">\(\gamma\)</span> are most useful in comparisons of associations between the same two variables in different samples or groups. For example, in Chapter <a href="c-3waytables.html#c-3waytables">9</a> we will calculate <span class="math inline">\(\gamma\)</span> for the variables in Table <a href="c-descr1.html#tab:t-investors">2.7</a> separately for men and women (see Table <a href="c-3waytables.html#tab:t-investors3">9.4</a>). These turn out to be very similar, so the strength of the association appears to be roughly similar in these two groups.</p>
<p>Three further observations complete our discussion of <span class="math inline">\(\gamma\)</span>:</p>
<ul>
<li><p>Since “high” values of a variable were defined as ones towards the bottom and right of a table, reversing the order in which the categories are listed will also reverse the interpretation of “high” and “low” and of a “negative” or “positive” association. Such a reversal for one variable will change the sign of <span class="math inline">\(\gamma\)</span> but not its absolute value. For example, in Table <a href="c-descr1.html#tab:t-investors">2.7</a> we could have listed the age groups from the oldest to the youngest, in which case we would have obtained <span class="math inline">\(\gamma=0.377\)</span> instead of <span class="math inline">\(\gamma=-0.377\)</span>. Reversing the ordering of both of the variables will give the same value of <span class="math inline">\(\gamma\)</span> as when neither is reversed. The nature and interpretation of the association remain unchanged in each case.</p></li>
<li><p><span class="math inline">\(\gamma\)</span> can also be used when one or both of the variables are dichotomous, but not when either is nominal and has more than two categories. If, for example, the table includes a nominal variable with four categories, there are 24 different and equally acceptable ways of ordering the categories, each giving a different value of <span class="math inline">\(\gamma\)</span> (or rather 12 different positive values and their negatives). An interpretation of the value obtained for any particular ordering is then entirely meaningless.</p></li>
<li><p><span class="math inline">\(\gamma\)</span> can also be treated as an estimate of the corresponding measure of association in a population from which the observed table is a sample. To emphasise this, the symbol <span class="math inline">\(\hat{\gamma}\)</span> is sometimes used for the sample statistic we have discussed here, reserving <span class="math inline">\(\gamma\)</span> for the population parameter. It is then also possible to define significance tests and confidence intervals for the population <span class="math inline">\(\gamma\)</span>. These are given, for example, in SPSS output for two-way tables. Here, however, we will not discuss them, but will treat <span class="math inline">\(\gamma\)</span> purely as a descriptive measure of association. Statistical inference on associations for two-way tables will be considered only in the context of a different test, introduced in Chapter <a href="c-tables.html#c-tables">4</a>.</p></li>
</ul>
</div>
</div>
<div id="s-descr1-1cont" class="section level2">
<h2><span class="header-section-number">2.5</span> Sample distributions of a single continuous variable</h2>
<div id="ss-descr1-1cont-tab" class="section level3">
<h3><span class="header-section-number">2.5.1</span> Tabular methods</h3>
<p>A table of frequencies and proportions or percentages is a concise and easily understandable summary of the sample distribution of a categorical variable or any variable for which only a small number of different values have been observed. On the other hand, applying the same idea to a continuous variable or a discrete variable with many different values is likely to be less useful, because all of the individual frequencies may be small. For example, in this section we illustrate the methods using the GDP variable in the country data introduced at the beginning of Section <a href="c-descr1.html#s-descr1-examples">2.2</a>. This has 99 different values among the 155 countries, 66 of these values appear only once, and the largest frequency (for 0.8) is five. A frequency table of these values would be entirely unenlightening.</p>
<table style="width:47%;">
<caption><span id="tab:t-gdp">Table 2.8: </span>Frequency distribution of GDP per capita in the country data.</caption>
<colgroup>
<col width="22%" />
<col width="16%" />
<col width="8%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left">GDP (thousands of dollars)</td>
<td align="center"><br />
 Frequency</td>
<td align="right"><br />
 %</td>
</tr>
<tr class="even">
<td align="left">less than 2.0</td>
<td align="center">49</td>
<td align="right">31.6</td>
</tr>
<tr class="odd">
<td align="left">2.0–4.9</td>
<td align="center">32</td>
<td align="right">20.6</td>
</tr>
<tr class="even">
<td align="left">5.0–9.9</td>
<td align="center">29</td>
<td align="right">18.7</td>
</tr>
<tr class="odd">
<td align="left">10.0–19.9</td>
<td align="center">21</td>
<td align="right">13.5</td>
</tr>
<tr class="even">
<td align="left">20.0–29.9</td>
<td align="center">19</td>
<td align="right">12.3</td>
</tr>
<tr class="odd">
<td align="left">30.0 or more</td>
<td align="center">5</td>
<td align="right">3.2</td>
</tr>
<tr class="even">
<td align="left">Total</td>
<td align="center">155</td>
<td align="right">99.9</td>
</tr>
</tbody>
</table>
<p>Instead, we can count the frequencies for some <em>intervals</em> of values. Table <a href="c-descr1.html#tab:t-gdp">2.8</a> shows an example of this for the GDP variable. The frequency on its first line shows that there are 49 countries with GDP per capita of less than $2000, the second line that there are 32 countries with the GDP per capita between $2000 and $4900 (these values included), and so on. We have thus in effect first created an ordinal categorical variable by grouping the original continuous GDP variable, and then drawn a frequency table of the grouped variable in the same way as we do for categorical variables. Some information about the distribution of the original, ungrouped variable will be lost in doing so, in that the exact values of the observations within each interval are obscured. This, however, is a minor loss compared to the benefit of obtaining a useful summary of the main features of the distribution.</p>
<p>The intervals must be <em>mutually exclusive</em>, so that no value belongs to more than one interval, and <em>exhaustive</em>, so that all values in the data belong to some interval. Otherwise the choice is arbitrary, in that we can choose the intervals in any way which is sensible and informative. Often this is a question of finding the right balance between too few categories (losing too much of the original information) and too many categories (making the table harder to read).</p>
</div>
<div id="ss-descr1-1cont-graphs" class="section level3">
<h3><span class="header-section-number">2.5.2</span> Graphical methods</h3>
<div id="histograms" class="section level4 unnumbered">
<h4>Histograms</h4>
<p><img src="gdp.png" alt=" Histogram of GDP per capita in the country data, together with the corresponding frequency polygon." />{width=“13.5cm”}</p>
<p>A <strong>histogram</strong> is the graphical version of a frequency table for a grouped variable, like that in Table <a href="c-descr1.html#tab:t-gdp">2.8</a>. Figure <a href="#fig:f-hist-gdp">2.4</a> shows a histogram for the GDP variable (the histogram consists of the bars; the lines belong to a different graph, the frequency polygon explained below). The basic idea of a histogram is very similar to that of the bar chart, except that now the bars touch each other to emphasise the fact that the original (ungrouped) variable is considered continuous. Because the grouped variable is ordinal, the bars of a histogram must be in the correct order.</p>
<p>A good choice of the grouping intervals of the variable and thus the number of bars in the histogram is important for the usefulness of the graph. If there are too few bars, too much information is obscured; if too many, the shape of the histogram may become confusingly irregular. Often the number of intervals used for a histogram will be larger than what would be sensible for a table like <a href="c-descr1.html#tab:t-gdp">2.8</a>. Furthermore, intervals like those in Table <a href="c-descr1.html#tab:t-gdp">2.8</a> are not even allowed in a histogram, because they are of different widths (of 2, 3, 5, 10 and 10 units for the first five, and unbounded for the last one). The intervals in a histogram must be of equal widths, because otherwise the visual information in it becomes distorted (at least unless the histogram is modified in ways not discussed here). For example, the intervals in Figure <a href="#fig:f-hist-gdp">2.4</a> (less than 2.5, 2.5–less than 5.0, 5.0–less than 7.5 etc.) are all 2.5 units wide. The exact choice can usually be left to computer packages such as SPSS which use automatic rules for choosing sensible intervals.</p>
</div>
<div id="frequency-polygons" class="section level4 unnumbered">
<h4>Frequency polygons</h4>
<p>Figure <a href="#fig:f-hist-gdp">2.4</a> also shows a <strong>frequency polygon</strong> of the GDP variable. This is obtained by drawing lines to connect the mid-points of the tops of the bars in a histogram. At each end of the histogram the lines are further connected to zero, as if the histogram had additional bars of zero height to the left and right of the smallest and largest observed categories. The result is a curve with a similar shape as the corresponding histogram, and its interpretation is similar to that of the histogram.</p>
<p>A histogram is usually preferable to a frequency polygon for presenting a single distribution, especially since histograms are typically much easier to produce in standard software such as SPSS. However, frequency polygons will later be useful for making comparisons between several distributions.</p>
</div>
<div id="stem-and-leaf-plots" class="section level4 unnumbered">
<h4>Stem and leaf plots</h4>
<p>A <strong>stem and leaf plot</strong> is a close relative of the histogram, and is used for much the same purposes, mostly in small data sets. It is easiest to explain through an example, so let us consider the GDP variable again. The stem and leaf plot for it is shown in Figure <a href="c-descr1.html#tab:t-stemgdp">2.9</a>. First, note that the values of the variable in the sample (from $500 to $37800, recorded as 0.5 to 37.8 thousands of dollars) have at most three significant digits. If the observations have too many digits to be convenient for a stem and leaf plot, they can be rounded first; for example, if the GDP figures had actually been recorded down to the last dollar, we would have rounded them to the nearest hundred dollars (as in Table <a href="c-descr1.html#tab:t-countrydata">2.14</a>) for the plot. The last digit (here hundreds of dollars) will determine the <em>leaves</em> for the plot, while other digits (here round thousands of dollars) will define the <em>stem</em>.</p>
<table>
<caption><span id="tab:t-stemgdp">Table 2.9: </span>Stem and leaf plot of GDP per capita in the country data (Stem=thousands of dollars, Leaf=hundreds of dollars).</caption>
<tbody>
<tr class="odd">
<td align="left"><code>0</code></td>
<td align="left"><code>5566677778888899</code></td>
</tr>
<tr class="even">
<td align="left"><code>1</code></td>
<td align="left"><code>0001112233334445566677788899999</code></td>
</tr>
<tr class="odd">
<td align="left"><code>2</code></td>
<td align="left"><code>1122234556799</code></td>
</tr>
<tr class="even">
<td align="left"><code>3</code></td>
<td align="left"><code>02334579</code></td>
</tr>
<tr class="odd">
<td align="left"><code>4</code></td>
<td align="left"><code>00013567889</code></td>
</tr>
<tr class="even">
<td align="left"><code>5</code></td>
<td align="left"><code>014588</code></td>
</tr>
<tr class="odd">
<td align="left"><code>6</code></td>
<td align="left"><code>0013334779</code></td>
</tr>
<tr class="even">
<td align="left"><code>7</code></td>
<td align="left"><code>002466</code></td>
</tr>
<tr class="odd">
<td align="left"><code>8</code></td>
<td align="left"><code>9</code></td>
</tr>
<tr class="even">
<td align="left"><code>9</code></td>
<td align="left"><code>000159</code></td>
</tr>
<tr class="odd">
<td align="left"><code>10</code></td>
<td align="left"><code>267</code></td>
</tr>
<tr class="even">
<td align="left"><code>11</code></td>
<td align="left"><code>12448</code></td>
</tr>
<tr class="odd">
<td align="left"><code>12</code></td>
<td align="left"><code>38</code></td>
</tr>
<tr class="even">
<td align="left"><code>13</code></td>
<td align="left"><code>139</code></td>
</tr>
<tr class="odd">
<td align="left"><code>14</code></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"><code>15</code></td>
<td align="left"><code>7</code></td>
</tr>
<tr class="odd">
<td align="left"><code>16</code></td>
<td align="left"><code>9</code></td>
</tr>
<tr class="even">
<td align="left"><code>17</code></td>
<td align="left"><code>8</code></td>
</tr>
<tr class="odd">
<td align="left"><code>18</code></td>
<td align="left"><code>0</code></td>
</tr>
<tr class="even">
<td align="left"><code>19</code></td>
<td align="left"><code>0028</code></td>
</tr>
<tr class="odd">
<td align="left"><code>20</code></td>
<td align="left"><code>0</code></td>
</tr>
<tr class="even">
<td align="left"><code>21</code></td>
<td align="left"><code>56</code></td>
</tr>
<tr class="odd">
<td align="left"><code>22</code></td>
<td align="left"><code>0</code></td>
</tr>
<tr class="even">
<td align="left"><code>23</code></td>
<td align="left"><code>247</code></td>
</tr>
<tr class="odd">
<td align="left"><code>24</code></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"><code>25</code></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left"><code>26</code></td>
<td align="left"><code>78</code></td>
</tr>
<tr class="even">
<td align="left"><code>27</code></td>
<td align="left"><code>4667</code></td>
</tr>
<tr class="odd">
<td align="left"><code>28</code></td>
<td align="left"><code>26</code></td>
</tr>
<tr class="even">
<td align="left"><code>29</code></td>
<td align="left"><code>0168</code></td>
</tr>
<tr class="odd">
<td align="left"><code>30</code></td>
<td align="left"><code>0</code></td>
</tr>
<tr class="even">
<td align="left"><code>31</code></td>
<td align="left"><code>1</code></td>
</tr>
<tr class="odd">
<td align="left"><code>32</code></td>
<td align="left"><code>7</code></td>
</tr>
<tr class="even">
<td align="left"><code>33</code></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left"><code>34</code></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"><code>35</code></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left"><code>36</code></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"><code>37</code></td>
<td align="left"><code>88</code></td>
</tr>
</tbody>
</table>
<p>The left-hand column in <a href="c-descr1.html#tab:t-stemgdp">2.9</a> lists the stem values in the data, from smallest (0) to the largest (37). Each data value with the same stem is represented on the same line by its leaf, i.e. its last digit. Thus the smallest value, 0.5 for Sierra Leone, is shown as a leaf “5” on the “0” stem, East Timor (another 0.5) as another “5” next to it, and so on up to the largest value 37.8 for Norway, shown as an “8” leaf on the “37” stem.</p>
<p>The stem and leaf plot is very similar to a histogram (try turning Figure <a href="c-descr1.html#tab:t-stemgdp">2.9</a> on its side, and compare to Figure <a href="#fig:f-hist-gdp">2.4</a>). It has the additional advantage that it also shows the actual numerical values of the observations. In some rather special cases this can reveal additional features of the data. Consider, for example, the plot shown in Figure <a href="c-descr1.html#tab:t-stemhours">2.10</a>. The variable here is the number of hours 86 respondents in a social survey (a small subset of all the respondents, drawn purely for this illustration) reported their <em>spouse</em> worked in the previous week. An obvious feature of the plot is the prevalence of zeroes as the leaves, especially the many observations with 40 reported hours. This suggests that most respondents probably did not carefully recall and add up the exact hours their spouses worked the previous week; instead, a round “40” is likely to be effectively a synonym for “my spouse has a regular nine-to-five job”. Such <em>digit preference</em> is quite common for many variables in surveys, and serves as a reminder that our measurements are not always as precise as they may appear.</p>
<table>
<caption><span id="tab:t-stemhours">Table 2.10: </span>Stem and leaf plot of the reported hours worked last week by the spouses of respondents in a social survey (the data are a sample from data from the U.S. General Survey; observations with less than 12 reported hours have been excluded). The stems and leaves indicate tens of hours and single hours respectively. The main disadvantage of a stem and leaf plot is that since every data value is shown separately, the plot can only be used when the sample size is relatively small. In such cases it is, however, a very useful and user-friendly graph. Also, “small” does not mean “tiny”. For example, the country data set has as many as <span class="math inline">\(n=155\)</span> observations, yet Figure <a href="c-descr1.html#tab:t-stemgdp">2.9</a> is still quite readable and fits on a single page.</caption>
<tbody>
<tr class="odd">
<td align="left"><code>1</code></td>
<td align="left"><code>55</code></td>
</tr>
<tr class="even">
<td align="left"><code>2</code></td>
<td align="left"><code>0000000555</code></td>
</tr>
<tr class="odd">
<td align="left"><code>3</code></td>
<td align="left"><code>00002222556889</code></td>
</tr>
<tr class="even">
<td align="left"><code>4</code></td>
<td align="left"><code>000000000000000000000000000000255556888</code></td>
</tr>
<tr class="odd">
<td align="left"><code>5</code></td>
<td align="left"><code>000000355</code></td>
</tr>
<tr class="even">
<td align="left"><code>6</code></td>
<td align="left"><code>000000555</code></td>
</tr>
<tr class="odd">
<td align="left"><code>7</code></td>
<td align="left"><code>022</code></td>
</tr>
</tbody>
</table>
<p><img src="box_gdp.png" alt=" An annotated box plot of GDP per capita in the country data (n=155)." />{width=“15cm”}</p>
</div>
<div id="box-plots" class="section level4 unnumbered">
<h4>Box plots</h4>
<p>A <strong>box plot</strong> differs from the graphs discussed so far in that it does not attempt to display the whole distribution, but only certain characteristics of it. The quantities included in a box plot are some of the summary statistics defined in Section <a href="c-descr1.html#s-descr1-nums">2.6</a>. To introduce the idea, one box plot is shown in Figure <a href="#fig:f-boxplot-gdp">2.5</a>. The variable considered here is again GDP per capita. The vertical axis shows possible values of the variable, and the plot itself contains the following elements:</p>
<ul>
<li><p>The line inside the central box is the <strong>median</strong> of the variable. Here it is 4.7.</p></li>
<li><p>The end points of the <strong>box</strong> are the <strong>first and third quartile</strong> of the variable, here 1.7 and 11.4 respectively. The length of the box is thus the interquartile range (IQR), here <span class="math inline">\(\text{IQR}=11.4-1.7=9.7\)</span>. The range of values covered by the box contains the middle 50% of the observations. Half of the countries in this sample have GDPs between $1700 and $11400.</p></li>
<li><p>The two lines extending from the box on either side are known as the <strong>whiskers</strong>. Their length is determined as follows:</p>
<ul>
<li><p>Calculate the value of 1.5 times the IQR. This is the maximum length of each whisker. Here this is <span class="math inline">\(1.5\times 9.7=14.6\)</span></p></li>
<li><p>The lower whisker extends to the smallest value (<strong>minimum</strong>) of the variable in the sample, or to the smallest value which is at most 1.5<span class="math inline">\(\times\)</span>IQR units below the first quartile, whichever is larger. Here the minimum is 0.5, which is less than 14.6 units below the first quartile of 1.7, so the lower whisker ends at 0.5.</p></li>
<li><p>The upper whisker extends to the largest value (<strong>maximum</strong>) in the sample, or to the largest value which is at most 1.5<span class="math inline">\(\times\)</span>IQR units above the third quartile, whichever is smaller. Here the maximum is 37.8, which is further than the maximum distance of 14.6 above the third quartile of 11.4 allowed for a whisker. Thus the upper whisker could be drawn at most to <span class="math inline">\(11.4+14.6=26\)</span>. In this sample there are actually no observations of exactly 26, so the whisker ends at the next smallest observed value, which is 23.7.</p></li>
</ul></li>
<li><p>If the mimimum is further than 1.5<span class="math inline">\(\times\)</span>IQR below the first quartile, or maximum further than 1.5<span class="math inline">\(\times\)</span>IQR above the third quartile, there are still observations which are not in the range spanned by the box and the whiskers. Such extreme observations are considered <strong>outliers</strong> in the plot. The values for each outlier are plotted separately as points. Here there are 15 different outlying values, all with large values of the variable (because in two cases two countries have the same value, these 15 points actually represent 17 countries).</p></li>
</ul>
<p>A box plot thus shows some of the main features of a distribution with the following visual cues:</p>
<ul>
<li><p>The central line shows a central value (the median) of the distribution.</p></li>
<li><p>The box shows the location of the central bulk (middle 50%) of the observations</p></li>
<li><p>The whiskers show the range of the regular (non-outlying) observations.</p></li>
<li><p>Very extreme values (outliers), if any, are shown individually.</p></li>
</ul>
<p>This can be quite effective for summarizing a distribution. For example, a box plot where the median line is not roughly in the middle of the box, or where one of the whiskers is much longer than the other, indicates that the sample distribution is skewed in the direction of the longer half of the box and the longer whisker. Here the distribution of GDP per capita is clearly positively skewed, as we have already observed. However, for a single distribution all such information and more can also be obtained from a histogram. It is instead for <em>comparisons</em> of distributions between two or more samples that box plots are particularly convenient, because it is easy to place two or more of them side by side. This will be illustrated later in Section <a href="c-means.html#ss-means-descr-graphs">7.2.1</a>.</p>
</div>
<div id="other-graphs-for-single-variables" class="section level4 unnumbered">
<h4>Other graphs for single variables</h4>
<p>Other types of graphs that are not described here are also sometimes used for displaying distributions. One of them is a <strong>pie chart</strong>, which shows the proportions of the levels of a categorical (or grouped continuous) variable as sectors of a circle. The relative area of a sector indicates the proportion of the category. We will not discuss pie charts further here, because we do not find them particularly useful (the same information can usually be presented more clearly in a table, bar chart or histogram). That, however, is partly a matter of taste, and there is nothing inherently wrong with (clearly and properly presented) pie charts.</p>
</div>
</div>
</div>
<div id="s-descr1-nums" class="section level2">
<h2><span class="header-section-number">2.6</span> Numerical descriptive statistics</h2>
<p>The tabular and graphical methods discussed above aim to display the whole sample distribution of a variable in an understandable form. The methods introduced in this section have a different purpose. Each of them is used to summarize some important single feature of the distribution in one number. In general, any such number calculated from the data is called a <strong>statistic</strong>. When it is used for data description, it is a <strong>descriptive statistic</strong>, also known as a <strong>summary statistic</strong>. This creates some terminological confusion, as the phrase “descriptive statistics” can mean either all statistical methods used for description or those statistics (i.e. numbers calculated from the data) with a descriptive purpose. The difference is usually unimportant or clear from the context.</p>
<p>The two salient features of a distribution for which we will define descriptive statistics are its <em>central tendency</em> and its <em>variation</em>.</p>
<div id="ss-descr1-nums-central" class="section level3">
<h3><span class="header-section-number">2.6.1</span> Measures of central tendency</h3>
<p>If you were allowed to know only one feature of the sample distribution of a variable, chances are you would ask for something like its most typical value, the middle value, or the average value — in short, you would be interested in a measure of <em>central tendency</em>. We will discuss three such measures below: the mode, the median and the mean (corresponding, respectively, to the phrases “most typical”, “middle” and “average” used above).</p>
<div id="the-mode" class="section level4 unnumbered">
<h4>The mode</h4>
<p>The <strong>mode</strong> is the value of the variable which occurs most often in the data, i.e. the one with the highest frequency. For example, Tables <a href="c-descr1.html#tab:t-region">2.1</a> and <a href="c-descr1.html#tab:t-democ">2.2</a> show that the mode of the region variable in the country data is “Africa” and the mode of the democracy score is 0. The GDP variable has two modes, 0.8 and 1.9, which both appear five times (a distribution can have several modes; one with two modes is said to be <em>bimodal</em>).</p>
<p>The mode can be used for variables of any measurement level. For <em>nominal</em> variables it is the only available measure of central tendency, as the median and the mean are not appropriate for such variables.</p>
<p>The mode does not need to be a <em>central</em> value in the sense that it can even be the largest or smallest value of the variable, if this occurs most often. This is the case for the democracy index in our example.</p>
<p>The mode is most useful for categorical variables, where the number of possible values is small, and the most common value thus has a high frequency. With continuous variables (like GDP) and discrete variables with many different values, the mode may be unstable and misleading. For example, it is perfectly possible that all but one value appear once each in a sample, and the mode is the value which happens to occur twice.</p>
</div>
<div id="the-median" class="section level4 unnumbered">
<h4>The median</h4>
<p>Suppose that the values of a variable in a sample are first ordered from the smallest to the largest. For example, in Table <a href="c-descr1.html#tab:t-countrydata">2.14</a> the countries are ordered in this way according to their GDP (starting from the bottom of the table). The <strong>median</strong> is the value which falls in the middle of this ordering, so that it divides the observed values into two halves. Because this requires a meaningful ordering of the values, the median is appropriate only for ordinal and interval-level variables, but not for nominal ones.</p>
<p>More specifically, suppose that there are <span class="math inline">\(n\)</span> observations, indexed from 1 for the smallest to <span class="math inline">\(n\)</span> for the largest. The index of the middle observation is then <span class="math inline">\((n+1)/2\)</span>. If <span class="math inline">\(n\)</span> is an odd number, the median is simply the observation in the ordered sample with this index. If <span class="math inline">\(n\)</span> is even, <span class="math inline">\((n+1)/2\)</span> falls between two whole numbers, and the median is the mean (of the kind defined below) of the observations with these two indices. For example, in the country data set <span class="math inline">\(n=155\)</span> (an odd number), and <span class="math inline">\((n+1)/2=78\)</span>, so the median is the value of the 78th observation in the ordered sample; if instead there had been <span class="math inline">\(n=156\)</span> countries, <span class="math inline">\((n+1)/2=78.5\)</span>, so the median would have been the mean of the 78th and 79th observations.</p>
<p>In the country data set the median of the democracy score is 6, and the median GDP is $4700 (the 78th observation in GDP order is Paraguay). In practice these are of course found using a a computer package like SPSS. For an ordinal categorical variable like the democracy score the median can also be found easily from the frequency table by considering the <em>cumulative percentages</em> (or proportions) of the categories. These are obtained by adding up the percentages up to and including each category, as shown in the last column of Table <a href="c-descr1.html#tab:t-democ">2.2</a>. The median is then the category in which the cumulative percentage reaches or passes 50%. For the democracy index this happens for the score of 6, which has a cumulative percentage of 50.9%.</p>
</div>
<div id="the-mean" class="section level4 unnumbered">
<h4>The mean</h4>
The <strong>mean</strong> is the best-known and most widely used measure of central tendency. It is also known as the <strong>average</strong>. To define the mean, we need to introduce our first pieces of mathematical notation. Suppose first that the variable of interest is denoted by <span class="math inline">\(Y\)</span>. In practice the variable is of course called something else, like GDP or Age or Income, but in the formulas below it is much more convenient to refer to any such variable generically by one letter (note also that the choice of the letter itself is arbitrary; for example, you may often see <span class="math inline">\(X\)</span> used instead of <span class="math inline">\(Y\)</span> when the mean is defined). Individual observations of <span class="math inline">\(Y\)</span> are denoted generically by <span class="math inline">\(Y_{i}\)</span>, where the subscript <span class="math inline">\(i\)</span> identifies a single subject. The values of <span class="math inline">\(i\)</span> range from <span class="math inline">\(1\)</span> to <span class="math inline">\(n\)</span>, so all of the observations in the sample are <span class="math inline">\(Y_{1}, Y_{2}, \dots, Y_{n}\)</span>, e.g. in the country example (with <span class="math inline">\(n=155\)</span>) <span class="math inline">\(Y_{1}, Y_{2}, \dots, Y_{155}\)</span>. The ordering of the observations is arbitrary here, so it might for example be the order in which they are listed in your SPSS data file. The mean <span class="math inline">\(\bar{Y}\)</span> (“Y-bar”) of the observations of <span class="math inline">\(Y\)</span> in the sample is defined as
\begin{equation}\bar{Y} = \frac{\sum Y_{i}}{n}.
\label{eq:Ybar}\end{equation}
<p>Here <span class="math inline">\(n\)</span> is again the sample size. The symbol <span class="math inline">\(\Sigma\)</span> (upper-case Greek letter “Sigma”) is a <em>summation symbol</em>, which indicates that we calculate the sum of all <span class="math inline">\(Y_{i}\)</span> (often this is stated more explicitly by the notation <span class="math inline">\(\sum_{i} Y_{i}\)</span> or <span class="math inline">\(\sum_{i=1}^{n} Y_{i}\)</span> to make it clear that the summation is over all the values of <span class="math inline">\(i\)</span>). In other words, (\ref{eq:Ybar}) is a concise expression for <span class="math display">\[\bar{Y}= \frac{Y_{1}+Y_{2}+\dots+Y_{n}}{n}\]</span> or, in English, “calculate the sum of all the observations of the variable <span class="math inline">\(Y\)</span> in the sample, and divide this sum by the number of observations to obtain the mean of <span class="math inline">\(Y\)</span> in the sample”. For example, for GDP per capita this calculation gives <span class="math display">\[\bar{Y}= \frac{37.8+37.8+32.7+\dots+0.6+0.5+0.5}{155}
=\frac{1335.1}{155}=8.6\]</span> (rounded to one decimal place), i.e. mean GDP among these countries is about $8600.</p>
<p>Because the mean requires arithmetical calculations (summation and division) on the observations <span class="math inline">\(Y_{i}\)</span>, it is strictly speaking only appropriate for interval level variables, but not for ordinal ones, for which the numbers of the categories are ordered labels rather than real numbers. However, it is common to see this instruction ignored and means calculated for ordinal variables, especially when they have a large number of categories (see also the discussion under “Measurement Levels” in Section <a href="c-intro.html#ss-intro-def-vartypes">1.2.2</a>). For example, the mean democracy score in our sample (using the codes 0–10 as its values) is 5.4. This may be used as a summary of the central tendency of the variable, but it should not be overinterpreted as its meaning is not quite as clear as that of, say, mean GDP.</p>
<p>For interval level variables the mean is by far the most commonly used measure of central tendency. It does, however, have one arguably undesirable feature. This is illustrated by the statistics for the GDP variable, as shown in Table <a href="c-descr1.html#tab:t-countries-sums">2.11</a>. Its mean ($8600) is clearly much larger than the median ($4700). This is due to the shape of the distribution of GDP, as revealed by Figure <a href="#fig:f-hist-gdp">2.4</a> or even more clearly by the stem and leaf plot of Figure <a href="c-descr1.html#tab:t-stemgdp">2.9</a>. While most of the countries are concentrated around a fairly narrow range of GDPs, there are also a number of countries with much larger GDPs. The ranges of values in the small and large ends of the values in a distribution are (for fairly obvious visual reasons) called the <strong>tails</strong> of the distribution. A distribution with a (much) longer tail in one end than the other is said to be <strong>skewed</strong>. A distribution like that of GDP in Figure <a href="#fig:f-hist-gdp">2.4</a>, with its long tail towards the large values, is said to be <strong>skewed to the right</strong> or <strong>positively skewed</strong>. A distribution shown in panel A of Figure <a href="#fig:f-skews">2.6</a> is <strong>skewed to the left</strong> (<strong>negatively skewed</strong>): while the examination marks of most students are relatively high, there are some students with very low marks. A distribution which has no clear skewness in either direction, like the distribution of typical weekly working hours in panel B of Figure <a href="#fig:f-skews">2.6</a> is (approximately) <strong>symmetric</strong>.</p>
<table style="width:99%;">
<caption><span id="tab:t-countries-sums">Table 2.11: </span>Summary statistics for the three variables in the country data. IQR=interquartile range; s.d.=standard deviation; *: inappropriate for a nominal variable; <span class="math inline">\(\dagger\)</span>: if the democracy index is treated as an interval-level variable.</caption>
<colgroup>
<col width="14%" />
<col width="13%" />
<col width="28%" />
<col width="11%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Measures</th>
<th align="center">of central</th>
<th align="center">tendency</th>
<th align="center">Measures</th>
<th align="center">of</th>
<th align="center">variation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Variable</td>
<td align="right">Mode</td>
<td align="center">Median</td>
<td align="center">Mean</td>
<td align="center">Range</td>
<td align="center">IQR</td>
<td align="center">s.d.</td>
</tr>
<tr class="even">
<td align="left">Region</td>
<td align="right">Africa</td>
<td align="center">*</td>
<td align="center">*</td>
<td align="center">*</td>
<td align="center">*</td>
<td align="center">*</td>
</tr>
<tr class="odd">
<td align="left">Democracy index</td>
<td align="right">0</td>
<td align="center">6</td>
<td align="center">5.4<span class="math inline">\(^{\dagger}\)</span></td>
<td align="center">10<span class="math inline">\(^{\dagger}\)</span></td>
<td align="center">8<span class="math inline">\(^{\dagger}\)</span></td>
<td align="center">3.9<span class="math inline">\(^{\dagger}\)</span></td>
</tr>
<tr class="even">
<td align="left">GDP per capita</td>
<td align="right">$800 and $1900</td>
<td align="center">$4700</td>
<td align="center">$8600</td>
<td align="center">$37300</td>
<td align="center">$9700</td>
<td align="center">$9450</td>
</tr>
</tbody>
</table>
<p><img src="twohists.png" title="fig:" alt=" Examples of a negatively skewed and an approximately symmetric sample distribution. Panel A shows the distribution of examination marks for MY451 (2003; n=419), and B shows the distribution of the number of hours a person usually works in their main job in the 3 per cent Individual Sample of Anonymized Records from the 2001 U.K. Census (n=867,016, respondents with hours 0 or not applicable omitted) Source of the data for panel B: Cathie Marsh Centre for Census and Survey Research, University of Manchester, http://www.ccsr.ac.uk/sars/." />{width=“14cm”}</p>
<p>The mean is almost always further in the direction of skewness than the median. That is why the mean of the positively skewed GDP variable is larger than its median. In general, a comparison between the two statistics will reveal the direction of any skewness, and give an indication of its magnitude. When the difference is large, as it is here, it is typically sensible to report both the mean and the median.</p>
<p>The mean is sensitive even to individual observations far in the tails of the distribution. Such observations, which are very different (much larger or smaller) from the rest of the data, are known as <strong>outliers</strong>. Even a single outlier can, if it is extreme enough, pull the mean far towards itself, even beyond the range of all the other observations, as in the following example:</p>
<p><em>Example: A sample with an outlier</em><br />
Suppose that an M.Sc. student, preparing her dissertation on elements of social capital in Canada, is examining various measures of community activities in a sample of fourty municipalities in the province of Manitoba.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> As part of an initial description of these communities, she wants to summarize their populations, which are</p>
<p>5, 79, 143, 226, 303, 317, 384, 417, 448, 505, 524, 525, 538, 619, 621, 629, 637, 760, 801, 906, 955, 959, 964, 1047, 1111, 1152, 1457, 1491, 1722, 1907, 2079, 2405, 2723, 3950, 4012, 4032, 4183, 4427, 12602, 619544.</p>
<p>The outlier in this case is the city of Winnipeg, whose population of nearly 620,000 is 49 times as large as that of the next largest municipality in the sample. With it included in the sample, the mean population of the 40 municipalities is about 17000; without it, the mean for the other 39 is 1600. The two numbers give rather different pictures of the size of an “average” community in the data (similar differences would probably be observed for other variables too, so the large city would be an outlier in many respects in a study like this). The median, on the other hand, is 906 for the 39 smaller communities, and 930.5 with Winnipeg included. It is thus essentially unaffected by the outlier, basically because it is only influenced by the fact that 619,554 is bigger than the mid-point of the data, but not by how much bigger it is.</p>
</div>
</div>
<div id="ss-descr1-nums-variation" class="section level3">
<h3><span class="header-section-number">2.6.2</span> Measures of variation</h3>
<p>A measure of central tendency is not a complete summary of a distribution, in that there can be distributions which have the same central tendency but which are different in some other respect. To illustrate this with a hypothetical example, suppose we are studying the students in three classrooms of the same grade at a local school. Each class has 14 students, and all students have just taken the same test, graded 1 (low) to 10 (high). The marks of the students are found to be as shown in Table <a href="c-descr1.html#tab:t-classmarks">2.12</a>.</p>
<p>Both the mean and the median of the marks are 6 in every class. However, the classes are otherwise clearly not similar. In particular, the <strong>variation</strong> (or <strong>dispersion</strong>) of the marks is very different. There is no variation at all in Class 1 where everyone has the same score, and quite a lot of variation in Class 3, while Class 2 seems to fall between the two. To capture this, some <strong>measure of variation</strong> will be needed. Three such measures are described here. All of them stricly speaking require the variable to be measured at an interval level, because they involve calculations of differences between its values. Using them on an ordinal variable is thus subject to similar cautions as for the mean above. These measures of variation are entirely inappropriate for nominal-level variables. There are some measures which can be used for such variables, but they are not described here.</p>
<table>
<caption><span id="tab:t-classmarks">Table 2.12: </span>A hypothetical examples of test marks of students in three classes.</caption>
<tbody>
<tr class="odd">
<td align="left">Class 1:</td>
<td align="left">6 6 6 6 6 6 6 6 6 6 6 6 6 6</td>
</tr>
<tr class="even">
<td align="left">Class 2:</td>
<td align="left">4 4 5 5 5 6 6 6 6 7 7 7 8 8</td>
</tr>
<tr class="odd">
<td align="left">Class 3:</td>
<td align="left">1 2 2 3 4 4 4 8 8 9 9 10 10 10</td>
</tr>
</tbody>
</table>
<div id="range" class="section level4 unnumbered">
<h4>Range</h4>
<p>The <strong>range</strong> of a variable is simply the difference between its largest and smallest observed values (the <strong>maximum</strong> and <strong>minimum</strong> in statistical terminology). In the class example above,</p>
<p>Class 1: Range <span class="math inline">\(= 6-6 =0\)</span><br />
Class 2: Range <span class="math inline">\(= 8-4 =4\)</span><br />
Class 3: Range <span class="math inline">\(= 10-1 =9\)</span></p>
<p>The measure is largest for Class 3 and smallest for Class 1, so it seems to capture the differences in variation suggested by an initial look at the numbers themselves. For Class 1 the range is 0, because all of the observations are the same. In general, any sensible measure of variation should be zero when there is no variation (all observations are identical), and all of the measures described here have that property.</p>
<p>In the country data, the range of GDP is $37800-$500=$37300, and the range of the democracy score (if we cautiously treat it as an interval-level variable) is 10-0=10.</p>
</div>
<div id="interquartile-range" class="section level4 unnumbered">
<h4>Interquartile range</h4>
<p>The range is often not a particularly useful measure of variation, because it depends <em>only</em> on the two extremes of the data. It is thus very sensitive to outliers. If, for example, there is one large outlier, the range will be large even if all of the other observations are very similar to each other.</p>
<p>One way to reduce the effects of outliers is to ignore the tails of the distribution and consider the variation only among the central range of the data. This idea is expressed in the <strong>Interquartile range</strong>. First we have to define the quartiles:</p>
<ul>
<li><p><strong>The first quartile</strong> is the value such that 25% (one quarter) of the observations are smaller than (or equal to) it, and 75% (three quarters) bigger than (or equal to) it.</p></li>
<li><p><strong>The third quartile</strong> is the value such that 75% of the observations are smaller than (or equal to) it, and 25% bigger than (or equal to) it.</p></li>
</ul>
<p>The quartiles are thus similar in spirit to the median. Just as the median divides the observations into two equal halves (those below and those above the median), the quartiles divide them into two groups at different points. For example, the first quartile divides the observations into the smallest 25% and the remaining largest 75%. (The median can thus also be described as the <em>second quartile</em>, and all of these statistics are special cases of a larger class of similar statistics known as <em>percentiles</em>.)</p>
<p>The interquartile range (IQR) is the difference between the third and the first quartile. It is the range of the middle 50% of the observations, leaving out the smallest 25% and the largest 25%. This effectively eliminates the effects of any outliers, so IQR is a useful measure of variation (often used together with the median as measure of central tendency) when there are serious outliers or when the distribution is very skewed.</p>
<p>For the class example the interquartile ranges are</p>
<p>Class 1: IQR <span class="math inline">\(= 6-6 =0\)</span><br />
Class 2: IQR <span class="math inline">\(= 7-5 =2\)</span><br />
Class 3: IQR <span class="math inline">\(= 9.25-2.75 =6.5\)</span></p>
<p>These are again in the expected order.<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a> For the country data, the first and third quartiles for GDP are 1.7 and 11.4 respectively, and IQR=11.4-1.7=9.7. For the democracy score the quartiles are 1 and 9, and IQR=8.</p>
</div>
<div id="standard-deviation" class="section level4 unnumbered">
<h4>Standard deviation</h4>
<p>The most commonly used measure of variation is based on the <strong>deviations</strong> <span class="math display">\[Y_{i}-\bar{Y}\]</span> where <span class="math inline">\(Y_{i}\)</span> again denotes an individual observation of a variable, and <span class="math inline">\(\bar{Y}\)</span> is its mean. A deviation is the difference between an individual observation and the average value in the sample. Table <a href="c-descr1.html#tab:t-sdex">2.13</a> shows the deviations for Class 3 in the class example, together with the other calculations discussed below. Here a negative deviation indicates that an observation is smaller than the mean of 6 (e.g. <span class="math inline">\(1-6=-5\)</span>), and a positive deviation that an observation is larger than the mean (e.g. <span class="math inline">\(10-6=+4\)</span>).</p>
<table>
<caption><span id="tab:t-sdex">Table 2.13: </span>Calculating the standard deviation of test marks for Class 3 in the class example at the beginning of Section <a href="c-descr1.html#ss-descr1-nums-variation">2.6.2</a>.</caption>
<tbody>
<tr class="odd">
<td align="left">Student</td>
<td align="right"><span class="math inline">\(Y_{i}\)</span></td>
<td align="right"><span class="math inline">\(Y_{i}-\bar{Y}\)</span></td>
<td align="right"><span class="math inline">\((Y_{i}-\bar{Y})^{2}\)</span></td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="right">1</td>
<td align="right"><span class="math inline">\(-5\)</span></td>
<td align="right">25</td>
</tr>
<tr class="odd">
<td align="left">2</td>
<td align="right">2</td>
<td align="right"><span class="math inline">\(-4\)</span></td>
<td align="right">16</td>
</tr>
<tr class="even">
<td align="left">3</td>
<td align="right">2</td>
<td align="right"><span class="math inline">\(-4\)</span></td>
<td align="right">16</td>
</tr>
<tr class="odd">
<td align="left">4</td>
<td align="right">3</td>
<td align="right"><span class="math inline">\(-3\)</span></td>
<td align="right">9</td>
</tr>
<tr class="even">
<td align="left">5</td>
<td align="right">4</td>
<td align="right"><span class="math inline">\(-2\)</span></td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="left">6</td>
<td align="right">4</td>
<td align="right"><span class="math inline">\(-2\)</span></td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="left">7</td>
<td align="right">4</td>
<td align="right"><span class="math inline">\(-2\)</span></td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="left">8</td>
<td align="right">8</td>
<td align="right">+2</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="left">9</td>
<td align="right">8</td>
<td align="right">+2</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="left">10</td>
<td align="right">9</td>
<td align="right">+3</td>
<td align="right">9</td>
</tr>
<tr class="even">
<td align="left">11</td>
<td align="right">9</td>
<td align="right">+3</td>
<td align="right">9</td>
</tr>
<tr class="odd">
<td align="left">12</td>
<td align="right">10</td>
<td align="right">+4</td>
<td align="right">16</td>
</tr>
<tr class="even">
<td align="left">13</td>
<td align="right">10</td>
<td align="right">+4</td>
<td align="right">16</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(14=n\)</span></td>
<td align="right">10</td>
<td align="right">+4</td>
<td align="right">16</td>
</tr>
<tr class="even">
<td align="left">Sum</td>
<td align="right"><span class="math inline">\(\sum Y_{i}=84\)</span></td>
<td align="right"><span class="math inline">\(\sum(Y_{i}-\bar{Y})=0\)</span></td>
<td align="right"><span class="math inline">\(\sum(Y_{i}-\bar{Y})^{2}=152\)</span></td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="right"><span class="math inline">\(\bar{Y}=84/14=6\)</span></td>
<td align="right"><span class="math inline">\(\sum(Y_{i}-\bar{Y})/n=0\)</span></td>
<td align="right"><span class="math inline">\(s^{2}=152/13=11.69\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"><span class="math inline">\(s=\sqrt{11.69}=3.4\)</span></td>
</tr>
</tbody>
</table>
<p>The deviations are clearly related to variation, as a sample with little variation will have small deviations (most observations are close to the mean) and one with a lot of variation will have many large deviations (many observations are far from the mean). All that remains is to aggregate them in some sensible way into a single number.</p>
An inappropriate summary of the deviations is their mean, i.e. <span class="math inline">\(\sum (Y_{i}-\bar{Y})/n\)</span>. In the class example this turns out to be zero (see the second column of Table <a href="c-descr1.html#tab:t-sdex">2.13</a>), and not by coincidence. It can be shown that the mean of the deviations is in fact zero for any set of numbers. This happens because positive and negative deviations will always exactly cancel out each other in the sum. This is clearly not what we want, because a negative deviation of, say, <span class="math inline">\(-2\)</span> (an observation two units below the mean) should be equally strong evidence of variation as a positive deviation of +2 (an observation two units above the mean). The signs of the deviations thus need to be eliminated somehow. Just dropping the negative signs (so that <span class="math inline">\(-2\)</span> becomes 2) means calculating the <em>absolute values</em> of the deviations, denoted <span class="math inline">\(|Y_{i}-\bar{Y}|\)</span>. Taking the mean of these gives the <strong>mean absolute deviation</strong> or MAD, defined as <span class="math display">\[\text{MAD}=\frac{\sum |Y_{i}-\bar{Y}|}{n}.\]</span> This is a perfectly sensible measure of variation, but it is not very commonly used. This is largely because absolute values are mathematically rather difficult to work with, and this would make MAD very inconvenient for more sophisticated analyses, where measures of variation will also be needed.<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a> Instead, we eliminate the signs of the deviations by using their squares <span class="math inline">\((Y_{i}-\bar{Y})^{2}\)</span>, i.e. by multiplying each deviation by itself (c.f. the third column of Table <a href="c-descr1.html#tab:t-sdex">2.13</a> for an illustration). These are used to calculate the <strong>variance</strong>, denoted <span class="math inline">\(s^{2}\)</span> and defined as
\begin{equation}s^{2} = \frac{\sum (Y_{i}-\bar{Y})^{2}}{n-1}.
\label{eq:samplevar}\end{equation}
This is (apart from the <span class="math inline">\(n-1\)</span> rather than <span class="math inline">\(n\)</span> as the divisor) essentially the mean of the squared deviations. Its units of measurement are also squares of the units of the original measurements. For example, the variance of the GDP variable, which is itself measured in (thousands of) dollars, is expressed in dollars squared. This is rather inconvenient for any meaningful interpretation. To obtain a measure of variation expressed in the original units, we can take the square root (indicated below by <span class="math inline">\(\sqrt{\; \; }\)</span>) of the variance. This statistic is the <strong>standard deviation</strong>, often abbreviated as S.D., denoted by <span class="math inline">\(s\)</span> and defined as
\begin{equation}s = \sqrt{\frac{\sum (Y_{i}-\bar{Y})^{2}}{n-1}.}
\label{eq:sd}\end{equation}
<p>For the class example, this is 0 for Class 1, 1.3 for Class 2, and 3.4 for class 3. In the country data, the standard deviation of GDP is $9450 and that of the democracy score (if it is treated as an interval-level variable) is 3.9, as shown in Table <a href="c-descr1.html#tab:t-countries-sums">2.11</a>.</p>
<p>Like the mean, the standard deviation is sensitive to outliers and skewness of the distribution, so sometimes other measures of variation (e.g. IQR or MAD) should be reported instead of, or in addition to it. Nevertheless, the standard deviation is by far the most commonly used measure of variation. One reason for this is that it is very important not just as a descriptive statistic but also as an element in several forms of statistical inference. For description it is typically less immediately interpretable than measures of central tendency. Often the most revealing descriptive uses of the standard deviation are in comparisons between samples, like in the class example above. The following is a real example of this kind, where variation was in fact of more interest than central tendency:</p>
<p><em>Example: Variation in rates of economic growth</em><br />
In an article titled “Dancing in step” on November 13th 2004, <em>The Economist</em> discussed a set of data (collected by the J. P. Morgan Chase bank) on the annual growth rates (in percentage points) of the Gross Domestic Products (GDP) of 30 countries for each year since 1971. Measures of central tendency, such as average growth rates for each country and each year, are clearly interesting in this case. However, most of the discussion in the article concerned <em>variation</em> in growth rates, measured by their standard deviation across countries for each year, and especially changes in this variation over time. The standard deviation of growth rates was around 3–5 percentage points for every year until the early 1990s, had fallen to about 2 percentage points in 2003, and was forecast to decline further in subsequent years. There had thus previously been a fair amount of variation in rates of economic growth (with some economies growing faster and some slower, some perhaps being in recession), whereas recently the growth rates had become more similar across countries. The article summarized this in its subtitle as “The world’s economies are more synchronised than ever before”, and went on to discuss the implications of this development for global economy.</p>
<p>The formula (\ref{eq:sd}) for the standard deviation involves the divisor <span class="math inline">\(n-1\)</span>, where the discussion leading up to it might make you expect <span class="math inline">\(n\)</span> instead. The reasons for this will be discussed briefly in Section <a href="c-contd.html#ss-contd-popdistrs-params">6.2.1</a>. The definition is not entirely consistent in that some textbooks do use <span class="math inline">\(n\)</span> instead of <span class="math inline">\(n-1\)</span>. The difference is of no great importance, and using either <span class="math inline">\(n\)</span> or <span class="math inline">\(n-1\)</span> would be fine for our purposes. Whenever <span class="math inline">\(n\)</span> is even moderately large, the difference between <span class="math inline">\(n\)</span> and <span class="math inline">\(n-1\)</span> is in any case small, and both definitions of standard deviation give very similar values.</p>
<p>Finally, measures of central tendency and measures of variation, even though they summarise the two most important features of a sample distribution of a variable, may still miss some important features of the distribution. Consider, for example, the class marks in Classes 2 and 3 in our hypothetical example. These are summarized by the bar charts of Figure <a href="#fig:f-classbars">2.7</a>. The distribution for Class 2 is symmetric and concentrated around the mean value of 6. The most noticeable feature of the marks in Class 3, on the other hand, is that there appear to be two distinct groups of students, one with very low scores and one with high scores. A similar feature was also noted in the distribution of the democracy index in the country data (c.f. Figure <a href="#fig:f-bars-democ">2.2</a>). This property would not be revealed by measures of central tendency or variation, so it is an illustration of why it is always sensible to also examine the whole distribution of a variable using frequency tables or graphical methods.</p>
<p><img src="classbars.png" alt=" Bar charts of the test marks in the class example at the beginning of Section <a href="c-descr1.html#ss-descr1-nums-variation">2.6.2</a> for Classes 2 (on the left) and 3 (on the right)." />{height=“8.3cm”}</p>
</div>
</div>
</div>
<div id="s-descr1-2cont" class="section level2">
<h2><span class="header-section-number">2.7</span> Associations which involve continuous variables</h2>
<p>Bivariate descriptive methods which are designed for situations where at least one of the two variables is continuous are not described here but in later sections:</p>
<ul>
<li><p>Explanatory variable is categorical and response variable continuous: Parallel histograms, frequency polygons and box plots (Section <a href="c-means.html#s-means-descr">7.2</a>).</p></li>
<li><p>Both explanatory and response variables are continuous: Scatter plots and line plots (Section <a href="c-regression.html#ss-regression-descr-plots">8.2.2</a>).</p></li>
</ul>
<p>We do not discuss the remaining possibility, where the explanatory variable is continuous and the response is categorical. The simplest and usually quite sufficient way to give an initial description of the associations in this case is to group the explanatory variable into a categorical variable and then apply the methods of Section <a href="c-descr1.html#s-descr1-2cat">2.4</a>.</p>
</div>
<div id="s-descr1-presentation" class="section level2">
<h2><span class="header-section-number">2.8</span> Presentation of tables and graphs</h2>
<p>The purpose of statistical tables and graphs is to communicate information correctly, clearly and effectively. If they do not do that, that is, if they leave the reader misled, confused or uninformed, they have failed and should not have been shown at all. Creating good tables and graphics is not only a matter of understanding the technical details described above. It also involves general principles of design and presentation. Most of these should be simple common sense but clearly are not, judging by the many entirely unhelpful tables and graphs appearing in all kinds of publications. This section discusses very briefly some principles of good practice in presenting descriptive statistics in tables and graphs. Much of the section is based on two books, <em>The Visual Display of Quantitative Information</em> by Edward R. Tufte (Graphics Press, 1983) and <em>Visual Revelations</em> by Howard Wainer (Copernicus, 1997). These can be consulted for further information and examples of both good and bad practice.</p>
<p>First, a reader of a table or graph should be able to understand what it is about:</p>
<ul>
<li><p>The variables should be labelled clearly. In particular, the names used in computer data files should not be used unless they are also understandable words. So even if a variable is called ATTDFOXH in your SPSS file, it should still be labelled “Attitude to foxhunting”or something similar in presentation. Similarly, the categories of variables should be labelled in words wherever appropriate.</p></li>
<li><p>Items such as the columns of a table or the vertical axis of a bar chart should also be labelled clearly (e.g. whether they are for frequencies or percentages).</p></li>
<li><p>More generally, a table or figure and its caption should be (within reason) as self-contained as possible, in that the reader should be able to understand them with little reference to the rest of the text for explanation (remember that tables and figures often float, i.e. they may appear on a different page from where they are referred to in the main text). This may also include giving the source of the data in a note or caption to the table or figure.</p></li>
</ul>
<p>Some guidelines for constructing tables are</p>
<ul>
<li><p>A table produced by software such as SPSS, although it contains the necessary numbers, is rarely suitable for presentation directly. Tables included in research reports should be retyped and reformatted.</p></li>
<li><p>The categories of the variable should be in a sensible order. For ordinal variables (including those obtained by grouping a continuous one), this should obviously be the natural ordering of the categories. For a nominal variable, the order can be chosen in whichever way is most useful for presentation. Often it makes sense to order categories from the largest to the smallest, typically leaving any “Others” category last.</p></li>
<li><p>If only proportions or percentages are shown, the sample size <span class="math inline">\(n\)</span> should also be reported, perhaps in a note or caption to the table. This will allow the reader to judge how informative the table is. A percentage of 20% is clearly richer information when it corresponds to a frequency of 2,000 in a sample 10,000 than when it means 2 out of 10 observations. When <span class="math inline">\(n\)</span> is very small, proportions and percentages should be avoided altogether: reporting 1 out 7 as 14.3% is simply nonsensical.</p></li>
<li><p>Proportions and percentages can and should be rounded. It is rarely necessary to see percentages with more than one decimal place, if even that.</p></li>
</ul>
<p>With graphs, it is always useful to bear in mind Wainer’s principle:</p>
<p><strong>The aim of good data graphics is to</strong><br />
<strong>display data accurately and clearly</strong></p>
<p>The way to produce <em>bad</em> graphs is thus to break some part of this, for example by (1) not showing much data, (2) showing much that is not data, (3) showing the data inaccurately, or (4) obscuring the data. Graphs with these characteristics are a form of visual lying, distorting the graphical cues in a plot in ways which make it difficult or impossible to obtain accurate information from it.</p>
<p>One example of a lying graph already mentioned is the “cut” bar chart where the bars do not begin at zero. Another is the pseudo third dimension, an example of which is shown in Figure <a href="#fig:f-yuk">2.8</a>. The information presented in this graph is the same as that of Figure <a href="#fig:f-bars-region">2.1</a>, i.e. frequencies of different regions. These are represented by the heights of the bars. The additional information conveyed by the apparent thickness of the bars, represented in perspective to give an illusion of three-dimensional bars, is then — exactly nothing. The fake third dimension represents no data, and serves only to distort the real data that are being shown.</p>
<p>We can thus give a simple instruction: using a fake third dimension like the one in Figure <a href="#fig:f-yuk">2.8</a> is always wrong and not acceptable under any circumstances. This is true irrespective of the fact that such graphs are often seen and easily (often almost automatically) produced by software packages like Microsoft Excel. All this proves is that the programmers of those packages have little graphical sense, or perhaps that their companies have discovered that their customers are willing to pay for such “features” as colourful but pointless graphs. Indeed, many if not most of the graph styles provided by, say, Excel (exploding pie charts, doughnuts, cones, pyramids and so on) are entirely useless for accurate presentation of data.</p>
<p><img src="threeD.png" alt=" An example of an unacceptable graph: a bar chart with a pseudo three-dimensional effect. The data are the same as in Figure <a href="#fig:f-bars-region">2.1</a>." />{height=“8cm”}</p>
<p>An objection sometimes offered to such a severe rule is that bad graphs “look good”. This can be answered in two ways. First, a statistical graphic is not a decoration, but a tool for presenting information. Authors who confuse the two often end up displaying pretty colours and strange shapes to hide the lack of actual information in a graph. Second, even in an aesthetic sense a useful and accurate graph is preferable to a bad one, in the way that any well-designed object with a function tends to be more attractive than a badly designed one.</p>
<p>What, then, is the recipe for good graphics? Mostly this is just a matter of using basic graph types in a sensible and restrained manner, focusing on presenting information and avoiding all distracting decoration. Some such examples have been given earlier in this chapter. Other types of graphs are used to illustrate associations between variables, which we have not yet discussed. To anticipate that a little, Figure <a href="#fig:f-houseprices">2.9</a> shows one (good but not in any way exceptional) example of such graphs. It is a reproduction of a graph originally published in a survey of Spain in <em>The Economist</em>, and shows changes in average house prices in Spain, Germany and Britain between 1993 and 2003. Even without an introductory statistics course, the main message of Figure <a href="#fig:f-houseprices">2.9</a> is immediately clear: increases in Spanish house prices over the period have been comparable to those in Britain, with prices more than doubling in both countries, and very unlike those in Germany, where the prices have remained unchanged. Note also that the graph distinguishes between the lines for different countries by using different types of line. Different colours can of course be used instead, but their differences will become obscured if the graph is photocopied or printed in black and white.</p>
<p><img src="houseprices.png" alt=" An example of an informative graph: house prices in three countries between 1993 and 2003, indexed to 100 in 1993. Source: The Economist, June 26th, 2004. The numbers were estimated from the graph in the magazine, so they are approximate." />{width=“10cm”}</p>
<p>In addition to such modest but sensible and useful basic graphs, you may sometimes encounter inspired examples of special graphs which manage to describe particular data sets in exceptionally vivid and informative ways. Some such examples are shown at <a href="http://www.datavis.ca/gallery/index.php" class="uri">http://www.datavis.ca/gallery/index.php</a>, on the web page maintained by Michael Friendly at York University in Canada (unfortunately, however, the electronic images do not always do justice to the originals; crisper versions can be found in the books mentioned above). For example, the page shows what Edward Tufte has described as possibly “the best statistical graphic ever drawn”. This is Charles Joseph Minard’s graphical memorial, drawn in 1861, to the fate of Napoleon I’s army in their invasion of Russia in 1812. For contrast, the page also shows a number of examples of visual lying and other terrible graphs, including a mould-breaking re-intrepretation of the idea of a pie chart by Fox News, and a colourful effort that Tufte has called possibly “the worst graphic ever to find its way into print”. Clearly not all pictures tell us as much as a thousand words.</p>
</div>
<div id="s-descr1-app" class="section level2">
<h2><span class="header-section-number">2.9</span> Appendix: Country data</h2>
<p>The data used for illustration throughout this chapter are given in Table <a href="c-descr1.html#tab:t-countrydata">2.14</a>. The variables are defined as follows:</p>
<ul>
<li><p><strong>region</strong> indicates the macro region where the country is located, coded as 1=Africa, 2=Asia, 3=Europe, 4=Latin America, 5=Northern America, 6=Oceania. The list of regions and the assignment of countries to regions are those used by the UN Statistics Division (see &lt;unstats.un.org/unsd/methods/m49/m49.htm&gt;).</p></li>
<li><p><strong>democracy</strong> is a measure of institutionalised democracy by the Polity IV project.<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a> The values refer to each country’s classification in 2002. The variable has an 11-point scale from 0 (lowest level of democracy) to 10 (highest). Countries coded as being in the state of “interruption” or “interregnum” have been omitted.</p></li>
<li><p><strong>GDP</strong> is the country’s Gross Domestic Product per capita (in thousands of U.S. dollars), adjusted for purchasing power parity. The data were obtained from CIA’s <em>The World Factbook 2004</em> (<a href="https://www.cia.gov/library/publications/resources/the-world-factbook/" class="uri">https://www.cia.gov/library/publications/resources/the-world-factbook/</a>). The figures refer to slightly different years for different countries.</p></li>
</ul>
<p>The data set contains those 155 countries for which recent data on all of the three variables were available at the time the example created.</p>
<table>
<caption><span id="tab:t-countrydata">Table 2.14: </span></caption>
<thead>
<tr class="header">
<th align="left">Country</th>
<th align="right">R</th>
<th align="right">D</th>
<th align="right">GDP</th>
<th align="left">Country</th>
<th align="right">R</th>
<th align="right">D</th>
<th align="right">GDP</th>
<th align="left">Country</th>
<th align="right">R</th>
<th align="right">D</th>
<th align="right">GDP</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Norway</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">37.8</td>
<td align="left">Bulgaria</td>
<td align="right">3</td>
<td align="right">9</td>
<td align="right">7.6</td>
<td align="left">Pakistan</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">2.1</td>
</tr>
<tr class="even">
<td align="left">USA</td>
<td align="right">5</td>
<td align="right">10</td>
<td align="right">37.8</td>
<td align="left">Thailand</td>
<td align="right">2</td>
<td align="right">9</td>
<td align="right">7.4</td>
<td align="left">Angola</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1.9</td>
</tr>
<tr class="odd">
<td align="left">Switzerland</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">32.7</td>
<td align="left">Namibia</td>
<td align="right">1</td>
<td align="right">6</td>
<td align="right">7.2</td>
<td align="left">Bangladesh</td>
<td align="right">2</td>
<td align="right">6</td>
<td align="right">1.9</td>
</tr>
<tr class="even">
<td align="left">Denmark</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">31.1</td>
<td align="left">Iran</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="right">7.0</td>
<td align="left">Cambodia</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">1.9</td>
</tr>
<tr class="odd">
<td align="left">Austria</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">30.0</td>
<td align="left">Romania</td>
<td align="right">3</td>
<td align="right">8</td>
<td align="right">7.0</td>
<td align="left">Sudan</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1.9</td>
</tr>
<tr class="even">
<td align="left">Canada</td>
<td align="right">5</td>
<td align="right">10</td>
<td align="right">29.8</td>
<td align="left">Tunisia</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">6.9</td>
<td align="left">Zimbabwe</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1.9</td>
</tr>
<tr class="odd">
<td align="left">Ireland</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">29.6</td>
<td align="left">Macedonia</td>
<td align="right">3</td>
<td align="right">9</td>
<td align="right">6.7</td>
<td align="left">Burma</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">1.8</td>
</tr>
<tr class="even">
<td align="left">Belgium</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">29.1</td>
<td align="left">Turkey</td>
<td align="right">2</td>
<td align="right">8</td>
<td align="right">6.7</td>
<td align="left">Cameroon</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1.8</td>
</tr>
<tr class="odd">
<td align="left">Australia</td>
<td align="right">6</td>
<td align="right">10</td>
<td align="right">29.0</td>
<td align="left">Libya</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">6.4</td>
<td align="left">Mauritania</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1.8</td>
</tr>
<tr class="even">
<td align="left">Netherlands</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">28.6</td>
<td align="left">Colombia</td>
<td align="right">4</td>
<td align="right">7</td>
<td align="right">6.3</td>
<td align="left">Moldova</td>
<td align="right">3</td>
<td align="right">8</td>
<td align="right">1.8</td>
</tr>
<tr class="odd">
<td align="left">Japan</td>
<td align="right">2</td>
<td align="right">10</td>
<td align="right">28.2</td>
<td align="left">Kazakhstan</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">6.3</td>
<td align="left">Mongolia</td>
<td align="right">2</td>
<td align="right">10</td>
<td align="right">1.8</td>
</tr>
<tr class="even">
<td align="left">UK</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">27.7</td>
<td align="left">Panama</td>
<td align="right">4</td>
<td align="right">9</td>
<td align="right">6.3</td>
<td align="left">Laos</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">1.7</td>
</tr>
<tr class="odd">
<td align="left">France</td>
<td align="right">3</td>
<td align="right">9</td>
<td align="right">27.6</td>
<td align="left">Belarus</td>
<td align="right">3</td>
<td align="right">0</td>
<td align="right">6.1</td>
<td align="left">Gambia</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1.7</td>
</tr>
<tr class="even">
<td align="left">Germany</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">27.6</td>
<td align="left">Algeria</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">6.0</td>
<td align="left">Uzbekistan</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">1.7</td>
</tr>
<tr class="odd">
<td align="left">Finland</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">27.4</td>
<td align="left">Dominican R.</td>
<td align="right">4</td>
<td align="right">8</td>
<td align="right">6.0</td>
<td align="left">Haiti</td>
<td align="right">4</td>
<td align="right">1</td>
<td align="right">1.6</td>
</tr>
<tr class="even">
<td align="left">Sweden</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">26.8</td>
<td align="left">Fiji</td>
<td align="right">6</td>
<td align="right">6</td>
<td align="right">5.8</td>
<td align="left">Kyrgyzstan</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">1.6</td>
</tr>
<tr class="odd">
<td align="left">Italy</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">26.7</td>
<td align="left">Turkmenistan</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">5.8</td>
<td align="left">Senegal</td>
<td align="right">1</td>
<td align="right">8</td>
<td align="right">1.6</td>
</tr>
<tr class="even">
<td align="left">Singapore</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">23.7</td>
<td align="left">Gabon</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">5.5</td>
<td align="left">Iraq</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">1.5</td>
</tr>
<tr class="odd">
<td align="left">Taiwan</td>
<td align="right">2</td>
<td align="right">9</td>
<td align="right">23.4</td>
<td align="left">Ukraine</td>
<td align="right">3</td>
<td align="right">7</td>
<td align="right">5.4</td>
<td align="left">Togo</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1.5</td>
</tr>
<tr class="even">
<td align="left">UAE</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">23.2</td>
<td align="left">Peru</td>
<td align="right">4</td>
<td align="right">9</td>
<td align="right">5.1</td>
<td align="left">Cote d’Ivoire</td>
<td align="right">1</td>
<td align="right">5</td>
<td align="right">1.4</td>
</tr>
<tr class="odd">
<td align="left">Spain</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">22.0</td>
<td align="left">China</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">5.0</td>
<td align="left">Nepal</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">1.4</td>
</tr>
<tr class="even">
<td align="left">NZ</td>
<td align="right">6</td>
<td align="right">10</td>
<td align="right">21.6</td>
<td align="left">Swaziland</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">4.9</td>
<td align="left">Uganda</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1.4</td>
</tr>
<tr class="odd">
<td align="left">Qatar</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">21.5</td>
<td align="left">El Salvador</td>
<td align="right">4</td>
<td align="right">7</td>
<td align="right">4.8</td>
<td align="left">Bhutan</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">1.3</td>
</tr>
<tr class="even">
<td align="left">Greece</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">20.0</td>
<td align="left">Venezuela</td>
<td align="right">4</td>
<td align="right">6</td>
<td align="right">4.8</td>
<td align="left">Djibouti</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">1.3</td>
</tr>
<tr class="odd">
<td align="left">Israel</td>
<td align="right">2</td>
<td align="right">10</td>
<td align="right">19.8</td>
<td align="left">Paraguay</td>
<td align="right">4</td>
<td align="right">7</td>
<td align="right">4.7</td>
<td align="left">N. Korea</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">1.3</td>
</tr>
<tr class="even">
<td align="left">Cyprus</td>
<td align="right">2</td>
<td align="right">10</td>
<td align="right">19.2</td>
<td align="left">Philippines</td>
<td align="right">2</td>
<td align="right">8</td>
<td align="right">4.6</td>
<td align="left">Rwanda</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1.3</td>
</tr>
<tr class="odd">
<td align="left">Kuwait</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">19.0</td>
<td align="left">Albania</td>
<td align="right">3</td>
<td align="right">7</td>
<td align="right">4.5</td>
<td align="left">Chad</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1.2</td>
</tr>
<tr class="even">
<td align="left">Slovenia</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">19.0</td>
<td align="left">Jordan</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">4.3</td>
<td align="left">Mozambique</td>
<td align="right">1</td>
<td align="right">6</td>
<td align="right">1.2</td>
</tr>
<tr class="odd">
<td align="left">Portugal</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">18.0</td>
<td align="left">Guatemala</td>
<td align="right">4</td>
<td align="right">8</td>
<td align="right">4.1</td>
<td align="left">Benin</td>
<td align="right">1</td>
<td align="right">6</td>
<td align="right">1.1</td>
</tr>
<tr class="even">
<td align="left">S. Korea</td>
<td align="right">2</td>
<td align="right">8</td>
<td align="right">17.8</td>
<td align="left">Egypt</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">4.0</td>
<td align="left">Burkina Faso</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">1.1</td>
</tr>
<tr class="odd">
<td align="left">Bahrain</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">16.9</td>
<td align="left">Guyana</td>
<td align="right">4</td>
<td align="right">6</td>
<td align="right">4.0</td>
<td align="left">C. Afr. R.</td>
<td align="right">1</td>
<td align="right">5</td>
<td align="right">1.1</td>
</tr>
<tr class="even">
<td align="left">Czech R.</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">15.7</td>
<td align="left">Morocco</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">4.0</td>
<td align="left">Kenya</td>
<td align="right">1</td>
<td align="right">8</td>
<td align="right">1.0</td>
</tr>
<tr class="odd">
<td align="left">Hungary</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">13.9</td>
<td align="left">Jamaica</td>
<td align="right">4</td>
<td align="right">9</td>
<td align="right">3.9</td>
<td align="left">Liberia</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">1.0</td>
</tr>
<tr class="even">
<td align="left">Slovakia</td>
<td align="right">3</td>
<td align="right">9</td>
<td align="right">13.3</td>
<td align="left">Sri Lanka</td>
<td align="right">2</td>
<td align="right">7</td>
<td align="right">3.7</td>
<td align="left">Tajikistan</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">1.0</td>
</tr>
<tr class="odd">
<td align="left">Oman</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">13.1</td>
<td align="left">Armenia</td>
<td align="right">2</td>
<td align="right">6</td>
<td align="right">3.5</td>
<td align="left">Mali</td>
<td align="right">1</td>
<td align="right">6</td>
<td align="right">.9</td>
</tr>
<tr class="even">
<td align="left">Uruguay</td>
<td align="right">4</td>
<td align="right">10</td>
<td align="right">12.8</td>
<td align="left">Azerbaijan</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">3.4</td>
<td align="left">Nigeria</td>
<td align="right">1</td>
<td align="right">4</td>
<td align="right">.9</td>
</tr>
<tr class="odd">
<td align="left">Estonia</td>
<td align="right">3</td>
<td align="right">7</td>
<td align="right">12.3</td>
<td align="left">Ecuador</td>
<td align="right">4</td>
<td align="right">6</td>
<td align="right">3.3</td>
<td align="left">Guinea-Bissau</td>
<td align="right">1</td>
<td align="right">5</td>
<td align="right">.8</td>
</tr>
<tr class="even">
<td align="left">Saudi Ar.</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">11.8</td>
<td align="left">Syria</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">3.3</td>
<td align="left">Madagascar</td>
<td align="right">1</td>
<td align="right">7</td>
<td align="right">.8</td>
</tr>
<tr class="odd">
<td align="left">Lithuania</td>
<td align="right">3</td>
<td align="right">10</td>
<td align="right">11.4</td>
<td align="left">Indonesia</td>
<td align="right">2</td>
<td align="right">8</td>
<td align="right">3.2</td>
<td align="left">Niger</td>
<td align="right">1</td>
<td align="right">4</td>
<td align="right">.8</td>
</tr>
<tr class="even">
<td align="left">Mauritius</td>
<td align="right">1</td>
<td align="right">10</td>
<td align="right">11.4</td>
<td align="left">Lesotho</td>
<td align="right">1</td>
<td align="right">8</td>
<td align="right">3.0</td>
<td align="left">Yemen</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">.8</td>
</tr>
<tr class="odd">
<td align="left">Argentina</td>
<td align="right">4</td>
<td align="right">8</td>
<td align="right">11.2</td>
<td align="left">Cuba</td>
<td align="right">4</td>
<td align="right">0</td>
<td align="right">2.9</td>
<td align="left">Zambia</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">.8</td>
</tr>
<tr class="even">
<td align="left">Poland</td>
<td align="right">3</td>
<td align="right">9</td>
<td align="right">11.1</td>
<td align="left">India</td>
<td align="right">2</td>
<td align="right">9</td>
<td align="right">2.9</td>
<td align="left">Comoros</td>
<td align="right">1</td>
<td align="right">4</td>
<td align="right">.7</td>
</tr>
<tr class="odd">
<td align="left">S. Africa</td>
<td align="right">1</td>
<td align="right">9</td>
<td align="right">10.7</td>
<td align="left">Equatorial G.</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">2.7</td>
<td align="left">Eritrea</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">.7</td>
</tr>
<tr class="even">
<td align="left">Croatia</td>
<td align="right">3</td>
<td align="right">7</td>
<td align="right">10.6</td>
<td align="left">Honduras</td>
<td align="right">4</td>
<td align="right">7</td>
<td align="right">2.6</td>
<td align="left">Ethiopia</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">.7</td>
</tr>
<tr class="odd">
<td align="left">Latvia</td>
<td align="right">3</td>
<td align="right">8</td>
<td align="right">10.2</td>
<td align="left">Georgia</td>
<td align="right">2</td>
<td align="right">5</td>
<td align="right">2.5</td>
<td align="left">Congo (Br.)</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">.7</td>
</tr>
<tr class="even">
<td align="left">Trinidad</td>
<td align="right">4</td>
<td align="right">10</td>
<td align="right">9.5</td>
<td align="left">Vietnam</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">2.5</td>
<td align="left">Burundi</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">.6</td>
</tr>
<tr class="odd">
<td align="left">Costa Rica</td>
<td align="right">4</td>
<td align="right">10</td>
<td align="right">9.1</td>
<td align="left">Bolivia</td>
<td align="right">4</td>
<td align="right">9</td>
<td align="right">2.4</td>
<td align="left">Malawi</td>
<td align="right">1</td>
<td align="right">6</td>
<td align="right">.6</td>
</tr>
<tr class="even">
<td align="left">Botswana</td>
<td align="right">1</td>
<td align="right">9</td>
<td align="right">9.0</td>
<td align="left">Nicaragua</td>
<td align="right">4</td>
<td align="right">8</td>
<td align="right">2.3</td>
<td align="left">Tanzania</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">.6</td>
</tr>
<tr class="odd">
<td align="left">Malaysia</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="right">9.0</td>
<td align="left">Ghana</td>
<td align="right">1</td>
<td align="right">7</td>
<td align="right">2.2</td>
<td align="left">East Timor</td>
<td align="right">2</td>
<td align="right">6</td>
<td align="right">.5</td>
</tr>
<tr class="even">
<td align="left">Mexico</td>
<td align="right">4</td>
<td align="right">8</td>
<td align="right">9.0</td>
<td align="left">PNG</td>
<td align="right">6</td>
<td align="right">10</td>
<td align="right">2.2</td>
<td align="left">Sierra Leone</td>
<td align="right">1</td>
<td align="right">5</td>
<td align="right">.5</td>
</tr>
<tr class="odd">
<td align="left">Russia</td>
<td align="right">3</td>
<td align="right">7</td>
<td align="right">8.9</td>
<td align="left">Serbia</td>
<td align="right">3</td>
<td align="right">7</td>
<td align="right">2.2</td>
<td align="left"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="even">
<td align="left">Brazil</td>
<td align="right">4</td>
<td align="right">8</td>
<td align="right">7.6</td>
<td align="left">Guinea</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">2.1</td>
<td align="left"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
</tbody>
</table>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>ESS Round 5: European Social Survey Round 5 Data (2010). Data file edition 2.0. Norwegian Social Science Data Services, Norway - Data Archive and distributor of ESS data.<a href="c-descr1.html#fnref2">↩</a></p></li>
<li id="fn3"><p>For recent findings, see for example Svallfors, S. (ed.) (2012), <em>Contested Welfare States: Welfare Attitudes in Europe and Beyond</em>. Stanford University Press.<a href="c-descr1.html#fnref3">↩</a></p></li>
<li id="fn4"><p>See, for example, Svallfors (1997), Words of welfare and attitudes to redistribution: A comparison of eight western nations, <em>European Sociological Review</em>, 13, 283-304; and Blekesaune and Quadagno (2003), Public attitudes towards welfare state policies: A comparative analysis of 24 nations, <em>European Sociological Review</em>, 19, 415-427.<a href="c-descr1.html#fnref4">↩</a></p></li>
<li id="fn5"><p>Lewellen, W. G., Lease, R. G., and Schlarbaum, G. G. (1977). “Patterns of investment strategy and behavior among individual investors”. <em>The Journal of Business</em>, <strong>50</strong>, 296–333. The published article gave only the total sample size, the marginal distributions of sex and age group, and conditional proportions for the short-term gains variable given sex and age group. These were used to create tables of frequencies separately for men and women (assuming further that the age distribution was the same for both), and Table <a href="c-descr1.html#tab:t-investors">2.7</a> was obtained by combining these. The resulting table is consistent with information in the article, apart from rounding error.<a href="c-descr1.html#fnref5">↩</a></p></li>
<li id="fn6"><p>This is a random sample of municipalities, obtained for this illustration from the 2001 census data provided by Statistics Canada at <a href="http://www.statcan.gc.ca" class="uri">http://www.statcan.gc.ca</a>.<a href="c-descr1.html#fnref6">↩</a></p></li>
<li id="fn7"><p>There is no need to worry about how the quartile values 9.25 and 2.75 for class 3 were calculated. Different software packages may in fact do that slightly differently; these values are from SPSS.<a href="c-descr1.html#fnref7">↩</a></p></li>
<li id="fn8"><p>In mathematical terms, the difficulty is that the absolute value function has no derivative at zero.<a href="c-descr1.html#fnref8">↩</a></p></li>
<li id="fn9"><p>Monty G. Marshall and Keith Jaggers (2002). <em>Polity IV Dataset</em>. <span class="math display">\[Computer file; version p4v2002\]</span> College Park, MD: Center for International Development and Conflict Management, University of Maryland.<a href="c-descr1.html#fnref9">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="c-intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="c-samples.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/kbenoit/coursepack-bookdown/edit/master/02-MY451-descr1.Rmd",
"text": null
},
"download": ["Coursepack-MY451.pdf", "Coursepack-MY451.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
